{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment.realuser import RealUserEnvironment\n",
    "from server.nlu import NLU\n",
    "from typing import Tuple\n",
    "from data.dataset import GraphDataset, ReimburseGraphDataset, DataAugmentationLevel\n",
    "from data.parsers.parserValueProvider import ReimbursementRealValueBackend\n",
    "from data.parsers.answerTemplateParser import AnswerTemplateParser\n",
    "from data.parsers.systemTemplateParser import SystemTemplateParser\n",
    "from data.parsers.logicParser import LogicTemplateParser\n",
    "from utils.utils import AutoSkipMode\n",
    "from algorithm.dqn.dqn import CustomDQN\n",
    "import torch\n",
    "from data.cache import Cache\n",
    "from gymnasium import spaces, Env\n",
    "from encoding.state import StateEncoding\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.core.config_store import ConfigStore\n",
    "from config import register_configs\n",
    "\n",
    "cs = ConfigStore.instance()\n",
    "register_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"reimburse_realdata_terminalobs\"\n",
    "ckpt_path = '/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_weights/run_1694965093/best_eval/weights/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env(data: GraphDataset) -> RealUserEnvironment:\n",
    "    # setup data & parsers\n",
    "    answerParser = AnswerTemplateParser()\n",
    "    logicParser = LogicTemplateParser()\n",
    "    sysParser = SystemTemplateParser()\n",
    "    valueBackend = ReimbursementRealValueBackend(a1_laender=data.a1_countries, data=data.hotel_costs)\n",
    "    nlu = NLU()\n",
    "\n",
    "    # setup env\n",
    "    env = RealUserEnvironment(dataset=data, nlu=nlu,\n",
    "                        sys_token=\"SYSTEM\", usr_token=\"USER\", sep_token=\"\",\n",
    "                        max_steps=50, max_reward=150, user_patience=2,\n",
    "                        answer_parser=answerParser, logic_parser=logicParser, value_backend=valueBackend,\n",
    "                        auto_skip=AutoSkipMode.NONE, stop_on_invalid_skip=False)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_class(path:str):\n",
    "    from pydoc import locate\n",
    "    class_instance = locate(path)\n",
    "    return class_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## NOTE: assumes already unzipped checkpoint!\n",
    "from config import DialogLogLevel, WandbLogLevel\n",
    "from algorithm.dqn.her import HindsightExperienceReplayWrapper\n",
    "import gymnasium as gym\n",
    "\n",
    "def load_model(ckpt_path: str, cfg_name: str, device: str, data: GraphDataset) -> Tuple[CustomDQN, StateEncoding]:\n",
    "    # load config\n",
    "    cfg_path = \"./conf/\"\n",
    "\n",
    "    with initialize(version_base=None, config_path=cfg_path):\n",
    "        # parse config\n",
    "        print(\"Parsing config...\")\n",
    "        cfg = compose(config_name=cfg_name)\n",
    "        # print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "        # disable logging\n",
    "        cfg.experiment.logging.dialog_log = DialogLogLevel.NONE\n",
    "        cfg.experiment.logging.wandb_log = WandbLogLevel.NONE\n",
    "        cfg.experiment.logging.log_interval = 9999999\n",
    "        cfg.experiment.logging.keep_checkpoints = 9\n",
    "\n",
    "        # load encodings\n",
    "        print(\"Loading encodings...\")\n",
    "        state_cfg = cfg.experiment.state\n",
    "        action_cfg = cfg.experiment.actions\n",
    "        cache = Cache(device=device, data=data, state_config=state_cfg, torch_compile=False)\n",
    "        encoding = StateEncoding(cache=cache, state_config=state_cfg, action_config=action_cfg, data=data)\n",
    "\n",
    "        # setup spaces\n",
    "        action_space = gym.spaces.Discrete(encoding.space_dims.num_actions)\n",
    "        if encoding.action_config.in_state_space == True:\n",
    "            # state space: max. node degree (#actions) x state dim\n",
    "            observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(encoding.space_dims.num_actions, encoding.space_dims.state_vector,)) #, dtype=np.float32)\n",
    "        else:\n",
    "            observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(encoding.space_dims.state_vector,)) #, dtype=np.float32)\n",
    "\n",
    "        class CustomEnv(Env):\n",
    "            def __init__(self, observation_space, action_space) -> None:\n",
    "                self.observation_space = observation_space\n",
    "                self.action_space = action_space\n",
    "        dummy_env = CustomEnv(observation_space=observation_space, action_space=action_space)\n",
    "\n",
    "        # setup model\n",
    "        print(\"Settung up model...\")\n",
    "        net_arch = OmegaConf.to_container(cfg.experiment.policy.net_arch)\n",
    "        net_arch['state_dims'] = encoding.space_dims # patch arguments\n",
    "        optim = OmegaConf.to_container(cfg.experiment.optimizer)\n",
    "        optim_class = to_class(optim.pop('class_path'))\n",
    "        lr = optim.pop('lr')\n",
    "        print(\"Optim ARGS:\", optim_class, lr, optim)\n",
    "        policy_kwargs = {\n",
    "            \"activation_fn\": to_class(cfg.experiment.policy.activation_fn),   \n",
    "            \"net_arch\": net_arch,\n",
    "            \"torch_compile\": cfg.experiment.torch_compile,\n",
    "            \"optimizer_class\": optim_class,\n",
    "            \"optimizer_kwargs\": optim\n",
    "        }\n",
    "        replay_buffer_kwargs = {\n",
    "            \"num_train_envs\": cfg.experiment.environment.num_train_envs,\n",
    "            \"batch_size\": cfg.experiment.algorithm.dqn.batch_size,\n",
    "            \"dataset\": data,\n",
    "            \"append_ask_action\": False,\n",
    "            # \"state_encoding\": state_encoding,\n",
    "            \"auto_skip\": AutoSkipMode.NONE,\n",
    "            \"normalize_rewards\": True,\n",
    "            \"stop_when_reaching_goal\": cfg.experiment.environment.stop_when_reaching_goal,\n",
    "            \"stop_on_invalid_skip\": cfg.experiment.environment.stop_on_invalid_skip,\n",
    "            \"max_steps\": cfg.experiment.environment.max_steps,\n",
    "            \"user_patience\": cfg.experiment.environment.user_patience,\n",
    "            \"sys_token\": cfg.experiment.environment.sys_token,\n",
    "            \"usr_token\": cfg.experiment.environment.usr_token,\n",
    "            \"sep_token\": cfg.experiment.environment.sep_token,\n",
    "            \"alpha\": cfg.experiment.algorithm.dqn.buffer.backend.alpha,\n",
    "            \"beta\": cfg.experiment.algorithm.dqn.buffer.backend.beta,\n",
    "            \"use_lap\": cfg.experiment.algorithm.dqn.buffer.backend.use_lap \n",
    "        }\n",
    "        replay_buffer_class = HindsightExperienceReplayWrapper\n",
    "        dqn_target_cls =  to_class(cfg.experiment.algorithm.dqn.targets._target_)\n",
    "        dqn_target_args = {'gamma': cfg.experiment.algorithm.dqn.gamma}\n",
    "        dqn_target_args.update(cfg.experiment.algorithm.dqn.targets) \n",
    "        model = CustomDQN(policy=to_class(cfg.experiment.policy._target_), policy_kwargs=policy_kwargs,\n",
    "                    target=dqn_target_cls(**dqn_target_args),\n",
    "                    seed=cfg.experiment.seed,\n",
    "                    env=dummy_env, \n",
    "                    batch_size=cfg.experiment.algorithm.dqn.batch_size,\n",
    "                    verbose=1, device=cfg.experiment.device,  \n",
    "                    learning_rate=lr, \n",
    "                    exploration_initial_eps=cfg.experiment.algorithm.dqn.eps_start, exploration_final_eps=cfg.experiment.algorithm.dqn.eps_end, exploration_fraction=cfg.experiment.algorithm.dqn.exploration_fraction,\n",
    "                    buffer_size=1, \n",
    "                    learning_starts=cfg.experiment.algorithm.dqn.warmup_turns,\n",
    "                    gamma=cfg.experiment.algorithm.dqn.gamma,\n",
    "                    train_freq=1, # how many rollouts to perform before training once (one rollout = num_train_envs steps)\n",
    "                    gradient_steps=max(cfg.experiment.environment.num_train_envs // cfg.experiment.training.every_steps, 1),\n",
    "                    target_update_interval=cfg.experiment.algorithm.dqn.target_network_update_frequency * cfg.experiment.environment.num_train_envs,\n",
    "                    max_grad_norm=cfg.experiment.algorithm.dqn.max_grad_norm,\n",
    "                    tensorboard_log=None,\n",
    "                    replay_buffer_class=replay_buffer_class,\n",
    "                    optimize_memory_usage=False,\n",
    "                    replay_buffer_kwargs=replay_buffer_kwargs,\n",
    "                    action_masking=cfg.experiment.actions.action_masking,\n",
    "                    actions_in_state_space=cfg.experiment.actions.in_state_space\n",
    "                ) \n",
    "        \n",
    "        # restore weights\n",
    "        print(\"Restoring weights...\")\n",
    "        ckpt_params = torch.load(f\"{ckpt_path}/policy.pth\", map_location=device)\n",
    "        model.policy.load_state_dict(ckpt_params)\n",
    "        model.policy.set_training_mode(False)\n",
    "        model.policy.eval()\n",
    "    return model, encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Statistics =====\n",
      "- files:  en/reimburse/test_graph.json en/reimburse/test_answers.json\n",
      "- synonyms: True\n",
      "- depth: 20  - degree: 13\n",
      "- answers: 162\n",
      "- questions: 173\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n"
     ]
    }
   ],
   "source": [
    "data = ReimburseGraphDataset('en/reimburse/test_graph.json', 'en/reimburse/test_answers.json', use_answer_synonyms=True, augmentation=DataAugmentationLevel.NONE, resource_dir='resources')\n",
    "user_env = load_env(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing config...\n",
      "Loading encodings...\n",
      "Loading Embedding (caching: False) encoding.text.sbert.SentenceEmbeddings ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tree embedding for nodes...\n",
      "Done\n",
      "Space dimensions: StateDims(state_vector=3932, action_vector=1, state_action_subvector=783, num_actions=14)\n",
      "Settung up model...\n",
      "Optim ARGS: <class 'torch.optim.adam.Adam'> 0.0001 {}\n",
      "Using cuda:0 device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "HER BUFFER BACKEND PrioritizedLAPReplayBuffer\n",
      "HER ENV!! TOKENS: SYSTEM: USER: \n",
      "ARCHITECUTRE OptimizedModule(\n",
      "  (_orig_mod): CustomDuelingQNetworkWithIntentPrediction(\n",
      "    (shared_net): ModuleList(\n",
      "      (0): Linear(in_features=3149, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (action_input_net): ModuleList(\n",
      "      (0): Linear(in_features=783, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (value_net): ModuleList(\n",
      "      (0): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    )\n",
      "    (advantage_net): ModuleList(\n",
      "      (0): Linear(in_features=8192, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    )\n",
      "    (intent_head): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
      "      (1): SELU()\n",
      "      (2): Dropout(p=0.25, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ARCHITECUTRE OptimizedModule(\n",
      "  (_orig_mod): CustomDuelingQNetworkWithIntentPrediction(\n",
      "    (shared_net): ModuleList(\n",
      "      (0): Linear(in_features=3149, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (action_input_net): ModuleList(\n",
      "      (0): Linear(in_features=783, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (value_net): ModuleList(\n",
      "      (0): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    )\n",
      "    (advantage_net): ModuleList(\n",
      "      (0): Linear(in_features=8192, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    )\n",
      "    (intent_head): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
      "      (1): SELU()\n",
      "      (2): Dropout(p=0.25, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Restoring weights...\n"
     ]
    }
   ],
   "source": [
    "model, state_encoding = load_model(ckpt_path=ckpt_path, cfg_name=cfg_name, device='cpu', data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_action(obs: dict) -> Tuple[int, bool]:\n",
    "    # encode observation\n",
    "    s = state_encoding.batch_encode(observation=[obs], sys_token=\"SYSTEM\", usr_token=\"USER\", sep_token=\"\") \n",
    "    # predict action & intent\n",
    "    action, intent = model.predict(observation=s, deterministic=True)\n",
    "    action = int(action)\n",
    "    intent = intent.item()\n",
    "\n",
    "    return action, intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What topic do you have questions about? You can either click on an answer from the suggested topics or enter your own text.\n",
      "  (policy: action 0, is faq: True)\n",
      "ASKING What topic do you have questions about? You can either click on an answer from the suggested topics or enter your own text.\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Are you going on an intracity trip or a business trip?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Did you get written permission from your supervisor?\n",
      "  (done: False)\n",
      "  (policy: action 2, is faq: True)\n",
      "SKIPPING\n",
      "-> TO What country are you traveling to?\n",
      "  (done: False)\n",
      "  (policy: action 0, is faq: True)\n",
      "ASKING What country are you traveling to?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO What city are you traveling to?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO {{COUNTRY\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Please check the current COVID-19 travel warnings travel restrictions from the foreign ministry and \n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO COVID-19: Business trips should be reduced to an absolute minimum and are only allowed when they are\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Are you planning to extend your trip with private travel?\n",
      "  (done: False)\n",
      "  (policy: action 0, is faq: True)\n",
      "ASKING Are you planning to extend your trip with private travel?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO {{PRIVATE_EXTENSION\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Which topic do you want to know more about?\n",
      "  (done: False)\n",
      "  (policy: action 4, is faq: True)\n",
      "SKIPPING\n",
      "-> TO How long is the business related portion of your travel?\n",
      "  (done: False)\n",
      "  (policy: action 0, is faq: True)\n",
      "ASKING How long is the business related portion of your travel?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO What country are you traveling to?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO {{COUNTRY\n",
      "  (done: False)\n",
      "  (policy: action 0, is faq: True)\n",
      "ASKING In {{ COUNTRY }}, you are entitled to {{ PERDIEM.AMOUNT(COUNTRY, CITY) }} €  per day, minus any free meals which you choose to decline.\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO {{TRIP_LENGTH\n"
     ]
    },
    {
     "ename": "VisitError",
     "evalue": "Error trying to process rule \"ge\":\n\n'>=' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/lark/visitors.py:122\u001b[0m, in \u001b[0;36mTransformer._call_userfunc\u001b[0;34m(self, tree, new_children)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m wrapper \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mvisit_wrapper(f, tree\u001b[39m.\u001b[39;49mdata, children, tree\u001b[39m.\u001b[39;49mmeta)\n\u001b[1;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/lark/visitors.py:501\u001b[0m, in \u001b[0;36m_vargs_inline\u001b[0;34m(f, _data, children, _meta)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_vargs_inline\u001b[39m(f, _data, children, _meta):\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49mchildren)\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/lark/visitors.py:479\u001b[0m, in \u001b[0;36m_VArgsWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 479\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mVisitError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb Cell 9\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkapweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m action, intent \u001b[39m=\u001b[39m next_action(obs)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkapweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  (policy: action \u001b[39m\u001b[39m{\u001b[39;00maction\u001b[39m}\u001b[39;00m\u001b[39m, is faq: \u001b[39m\u001b[39m{\u001b[39;00mintent\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkapweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m obs, reward, done \u001b[39m=\u001b[39m user_env\u001b[39m.\u001b[39;49mstep(action\u001b[39m=\u001b[39;49maction)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkapweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  (done: \u001b[39m\u001b[39m{\u001b[39;00mdone\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mount/arbeitsdaten41/projekte/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/environment/base.py:319\u001b[0m, in \u001b[0;36mBaseEnv.step\u001b[0;34m(self, action, replayed_user_utterance)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39m# handle logic node auto-transitioning here\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m--> 319\u001b[0m     reward, logic_done, did_handle_logic_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_logic_and_varupdate_nodes(reward)\n\u001b[1;32m    320\u001b[0m     \u001b[39mif\u001b[39;00m did_handle_logic_node:\n\u001b[1;32m    321\u001b[0m         done \u001b[39m=\u001b[39m logic_done\n",
      "File \u001b[0;32m/mount/arbeitsdaten41/projekte/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/environment/base.py:416\u001b[0m, in \u001b[0;36mBaseEnv.handle_logic_and_varupdate_nodes\u001b[0;34m(self, reward)\u001b[0m\n\u001b[1;32m    414\u001b[0m rhs \u001b[39m=\u001b[39m answer\u001b[39m.\u001b[39mtext\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mDEFAULT\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m rhs: \u001b[39m# handle DEFAULT case last!\u001b[39;00m\n\u001b[0;32m--> 416\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fillLogicTemplate(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mlhs\u001b[39m}\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m{\u001b[39;49;00mrhs\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m):\n\u001b[1;32m    417\u001b[0m         \u001b[39m# evaluates to True, follow this path!\u001b[39;00m\n\u001b[1;32m    418\u001b[0m         default_answer \u001b[39m=\u001b[39m answer\n\u001b[1;32m    419\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/mount/arbeitsdaten41/projekte/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/environment/base.py:471\u001b[0m, in \u001b[0;36mBaseEnv._fillLogicTemplate\u001b[0;34m(self, delexicalized_utterance)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fillLogicTemplate\u001b[39m(\u001b[39mself\u001b[39m, delexicalized_utterance: \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 471\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogicParser\u001b[39m.\u001b[39;49mparse_template(delexicalized_utterance, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_backend, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbst)\n",
      "File \u001b[0;32m/mount/arbeitsdaten41/projekte/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/data/parsers/logicParser.py:63\u001b[0m, in \u001b[0;36mLogicTemplateParser.parse_template\u001b[0;34m(self, template, backend, bst)\u001b[0m\n\u001b[1;32m     59\u001b[0m parse_tree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparser\u001b[39m.\u001b[39mparse(template)\n\u001b[1;32m     60\u001b[0m \u001b[39m# print(parse_tree.pretty())\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m# fill in constants, evaluate variables + functions\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m LogicTransformer(backend, bst)\u001b[39m.\u001b[39;49mtransform(parse_tree)\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/lark/visitors.py:161\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, tree)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, tree: Tree[_Leaf_T]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _Return_T:\n\u001b[1;32m    160\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTransform the given tree, and return the final result\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 161\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform_tree(tree)\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/lark/visitors.py:156\u001b[0m, in \u001b[0;36mTransformer._transform_tree\u001b[0;34m(self, tree)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform_tree\u001b[39m(\u001b[39mself\u001b[39m, tree):\n\u001b[0;32m--> 156\u001b[0m     children \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform_children(tree\u001b[39m.\u001b[39;49mchildren))\n\u001b[1;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_userfunc(tree, children)\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/lark/visitors.py:146\u001b[0m, in \u001b[0;36mTransformer._transform_children\u001b[0;34m(self, children)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m children:\n\u001b[1;32m    145\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(c, Tree):\n\u001b[0;32m--> 146\u001b[0m         res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform_tree(c)\n\u001b[1;32m    147\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__visit_tokens__ \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(c, Token):\n\u001b[1;32m    148\u001b[0m         res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_userfunc_token(c)\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/lark/visitors.py:157\u001b[0m, in \u001b[0;36mTransformer._transform_tree\u001b[0;34m(self, tree)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform_tree\u001b[39m(\u001b[39mself\u001b[39m, tree):\n\u001b[1;32m    156\u001b[0m     children \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_children(tree\u001b[39m.\u001b[39mchildren))\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_userfunc(tree, children)\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/lark/visitors.py:128\u001b[0m, in \u001b[0;36mTransformer._call_userfunc\u001b[0;34m(self, tree, new_children)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mraise\u001b[39;00m VisitError(tree\u001b[39m.\u001b[39mdata, tree, e)\n",
      "\u001b[0;31mVisitError\u001b[0m: Error trying to process rule \"ge\":\n\n'>=' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "obs = user_env.reset()\n",
    "done = False\n",
    "\n",
    "while not done and user_env.current_user_utterance != \"exit\":\n",
    "    action, intent = next_action(obs)\n",
    "    print(f\"  (policy: action {action}, is faq: {intent})\")\n",
    "    obs, reward, done = user_env.step(action=action)\n",
    "    print(f\"  (done: {done})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RealUserEnvironment' object has no attribute 'current_episode_log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkapweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m user_env\u001b[39m.\u001b[39;49mcurrent_episode_log\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RealUserEnvironment' object has no attribute 'current_episode_log'"
     ]
    }
   ],
   "source": [
    "user_env.current_episode_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DialogNode.LOGIC(key: 16378316272591567, answers: 2, questions: 0)\n",
       "        - connected_node: None\n",
       "        - text: {{PRIVATE_EXTENSION\n",
       "        "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_env.current_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cts_en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
