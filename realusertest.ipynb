{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment.realuser import RealUserEnvironment\n",
    "from typing import Tuple\n",
    "from data.dataset import GraphDataset, ReimburseGraphDataset, DataAugmentationLevel\n",
    "from data.parsers.parserValueProvider import RealValueBackend\n",
    "from data.parsers.answerTemplateParser import AnswerTemplateParser\n",
    "from data.parsers.systemTemplateParser import SystemTemplateParser\n",
    "from data.parsers.logicParser import LogicTemplateParser\n",
    "from utils.utils import AutoSkipMode\n",
    "from algorithm.dqn.dqn import CustomDQN\n",
    "import torch\n",
    "from data.cache import Cache\n",
    "from gymnasium import spaces, Env\n",
    "from encoding.state import StateEncoding\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.core.config_store import ConfigStore\n",
    "from config import register_configs\n",
    "\n",
    "cs = ConfigStore.instance()\n",
    "register_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"reimburse_realdata_terminalobs\"\n",
    "ckpt_path = '/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_weights/run_1694965093/best_eval/weights/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env(data: GraphDataset) -> RealUserEnvironment:\n",
    "    # setup data & parsers\n",
    "    answerParser = AnswerTemplateParser()\n",
    "    logicParser = LogicTemplateParser()\n",
    "    sysParser = SystemTemplateParser()\n",
    "    valueBackend = RealValueBackend(a1_laender=data.a1_countries, data=data.hotel_costs)\n",
    "\n",
    "    # setup env\n",
    "    env = RealUserEnvironment(dataset=data, \n",
    "                        sys_token=\"SYSTEM\", usr_token=\"USER\", sep_token=\"\",\n",
    "                        max_steps=50, max_reward=150, user_patience=2,\n",
    "                        answer_parser=answerParser, logic_parser=logicParser, value_backend=valueBackend,\n",
    "                        auto_skip=AutoSkipMode.NONE, stop_on_invalid_skip=False)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_class(path:str):\n",
    "    from pydoc import locate\n",
    "    class_instance = locate(path)\n",
    "    return class_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## NOTE: assumes already unzipped checkpoint!\n",
    "from config import DialogLogLevel, WandbLogLevel\n",
    "from algorithm.dqn.her import HindsightExperienceReplayWrapper\n",
    "import gymnasium as gym\n",
    "\n",
    "def load_model(ckpt_path: str, cfg_name: str, device: str, data: GraphDataset) -> Tuple[CustomDQN, StateEncoding]:\n",
    "    # load config\n",
    "    cfg_path = \"./conf/\"\n",
    "\n",
    "    with initialize(version_base=None, config_path=cfg_path):\n",
    "        # parse config\n",
    "        print(\"Parsing config...\")\n",
    "        cfg = compose(config_name=cfg_name)\n",
    "        # print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "        # disable logging\n",
    "        cfg.experiment.logging.dialog_log = DialogLogLevel.NONE\n",
    "        cfg.experiment.logging.wandb_log = WandbLogLevel.NONE\n",
    "        cfg.experiment.logging.log_interval = 9999999\n",
    "        cfg.experiment.logging.keep_checkpoints = 9\n",
    "\n",
    "        # load encodings\n",
    "        print(\"Loading encodings...\")\n",
    "        state_cfg = cfg.experiment.state\n",
    "        action_cfg = cfg.experiment.actions\n",
    "        cache = Cache(device=device, data=data, state_config=state_cfg, torch_compile=False)\n",
    "        encoding = StateEncoding(cache=cache, state_config=state_cfg, action_config=action_cfg, data=data)\n",
    "\n",
    "        # setup spaces\n",
    "        action_space = gym.spaces.Discrete(encoding.space_dims.num_actions)\n",
    "        if encoding.action_config.in_state_space == True:\n",
    "            # state space: max. node degree (#actions) x state dim\n",
    "            observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(encoding.space_dims.num_actions, encoding.space_dims.state_vector,)) #, dtype=np.float32)\n",
    "        else:\n",
    "            observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(encoding.space_dims.state_vector,)) #, dtype=np.float32)\n",
    "\n",
    "        class CustomEnv(Env):\n",
    "            def __init__(self, observation_space, action_space) -> None:\n",
    "                self.observation_space = observation_space\n",
    "                self.action_space = action_space\n",
    "        dummy_env = CustomEnv(observation_space=observation_space, action_space=action_space)\n",
    "\n",
    "        # setup model\n",
    "        print(\"Settung up model...\")\n",
    "        net_arch = OmegaConf.to_container(cfg.experiment.policy.net_arch)\n",
    "        net_arch['state_dims'] = encoding.space_dims # patch arguments\n",
    "        optim = OmegaConf.to_container(cfg.experiment.optimizer)\n",
    "        optim_class = to_class(optim.pop('class_path'))\n",
    "        lr = optim.pop('lr')\n",
    "        print(\"Optim ARGS:\", optim_class, lr, optim)\n",
    "        policy_kwargs = {\n",
    "            \"activation_fn\": to_class(cfg.experiment.policy.activation_fn),   \n",
    "            \"net_arch\": net_arch,\n",
    "            \"torch_compile\": cfg.experiment.torch_compile,\n",
    "            \"optimizer_class\": optim_class,\n",
    "            \"optimizer_kwargs\": optim\n",
    "        }\n",
    "        replay_buffer_kwargs = {\n",
    "            \"num_train_envs\": cfg.experiment.environment.num_train_envs,\n",
    "            \"batch_size\": cfg.experiment.algorithm.dqn.batch_size,\n",
    "            \"dataset\": data,\n",
    "            \"append_ask_action\": False,\n",
    "            # \"state_encoding\": state_encoding,\n",
    "            \"auto_skip\": AutoSkipMode.NONE,\n",
    "            \"normalize_rewards\": True,\n",
    "            \"stop_when_reaching_goal\": cfg.experiment.environment.stop_when_reaching_goal,\n",
    "            \"stop_on_invalid_skip\": cfg.experiment.environment.stop_on_invalid_skip,\n",
    "            \"max_steps\": cfg.experiment.environment.max_steps,\n",
    "            \"user_patience\": cfg.experiment.environment.user_patience,\n",
    "            \"sys_token\": cfg.experiment.environment.sys_token,\n",
    "            \"usr_token\": cfg.experiment.environment.usr_token,\n",
    "            \"sep_token\": cfg.experiment.environment.sep_token,\n",
    "            \"alpha\": cfg.experiment.algorithm.dqn.buffer.backend.alpha,\n",
    "            \"beta\": cfg.experiment.algorithm.dqn.buffer.backend.beta,\n",
    "            \"use_lap\": cfg.experiment.algorithm.dqn.buffer.backend.use_lap \n",
    "        }\n",
    "        replay_buffer_class = HindsightExperienceReplayWrapper\n",
    "        dqn_target_cls =  to_class(cfg.experiment.algorithm.dqn.targets._target_)\n",
    "        dqn_target_args = {'gamma': cfg.experiment.algorithm.dqn.gamma}\n",
    "        dqn_target_args.update(cfg.experiment.algorithm.dqn.targets) \n",
    "        model = CustomDQN(policy=to_class(cfg.experiment.policy._target_), policy_kwargs=policy_kwargs,\n",
    "                    target=dqn_target_cls(**dqn_target_args),\n",
    "                    seed=cfg.experiment.seed,\n",
    "                    env=dummy_env, \n",
    "                    batch_size=cfg.experiment.algorithm.dqn.batch_size,\n",
    "                    verbose=1, device=cfg.experiment.device,  \n",
    "                    learning_rate=lr, \n",
    "                    exploration_initial_eps=cfg.experiment.algorithm.dqn.eps_start, exploration_final_eps=cfg.experiment.algorithm.dqn.eps_end, exploration_fraction=cfg.experiment.algorithm.dqn.exploration_fraction,\n",
    "                    buffer_size=1, \n",
    "                    learning_starts=cfg.experiment.algorithm.dqn.warmup_turns,\n",
    "                    gamma=cfg.experiment.algorithm.dqn.gamma,\n",
    "                    train_freq=1, # how many rollouts to perform before training once (one rollout = num_train_envs steps)\n",
    "                    gradient_steps=max(cfg.experiment.environment.num_train_envs // cfg.experiment.training.every_steps, 1),\n",
    "                    target_update_interval=cfg.experiment.algorithm.dqn.target_network_update_frequency * cfg.experiment.environment.num_train_envs,\n",
    "                    max_grad_norm=cfg.experiment.algorithm.dqn.max_grad_norm,\n",
    "                    tensorboard_log=None,\n",
    "                    replay_buffer_class=replay_buffer_class,\n",
    "                    optimize_memory_usage=False,\n",
    "                    replay_buffer_kwargs=replay_buffer_kwargs,\n",
    "                    action_masking=cfg.experiment.actions.action_masking,\n",
    "                    actions_in_state_space=cfg.experiment.actions.in_state_space\n",
    "                ) \n",
    "        \n",
    "        # restore weights\n",
    "        print(\"Restoring weights...\")\n",
    "        ckpt_params = torch.load(f\"{ckpt_path}/policy.pth\", map_location=device)\n",
    "        model.policy.load_state_dict(ckpt_params)\n",
    "        model.policy.set_training_mode(False)\n",
    "        model.policy.eval()\n",
    "    return model, encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Statistics =====\n",
      "- files:  en/reimburse/test_graph.json en/reimburse/test_answers.json\n",
      "- synonyms: True\n",
      "- depth: 20  - degree: 13\n",
      "- answers: 162\n",
      "- questions: 173\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n"
     ]
    }
   ],
   "source": [
    "data = ReimburseGraphDataset('en/reimburse/test_graph.json', 'en/reimburse/test_answers.json', use_answer_synonyms=True, augmentation=DataAugmentationLevel.NONE, resource_dir='resources')\n",
    "user_env = load_env(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing config...\n",
      "Loading encodings...\n",
      "Loading Embedding (caching: False) encoding.text.sbert.SentenceEmbeddings ...\n",
      "Building tree embedding for nodes...\n",
      "Done\n",
      "Space dimensions: StateDims(state_vector=3932, action_vector=1, state_action_subvector=783, num_actions=14)\n",
      "Settung up model...\n",
      "Optim ARGS: <class 'torch.optim.adam.Adam'> 0.0001 {}\n",
      "Using cuda:0 device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "HER BUFFER BACKEND PrioritizedLAPReplayBuffer\n",
      "HER ENV!! TOKENS: SYSTEM: USER: \n",
      "ARCHITECUTRE OptimizedModule(\n",
      "  (_orig_mod): CustomDuelingQNetworkWithIntentPrediction(\n",
      "    (shared_net): ModuleList(\n",
      "      (0): Linear(in_features=3149, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (action_input_net): ModuleList(\n",
      "      (0): Linear(in_features=783, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (value_net): ModuleList(\n",
      "      (0): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    )\n",
      "    (advantage_net): ModuleList(\n",
      "      (0): Linear(in_features=8192, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    )\n",
      "    (intent_head): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
      "      (1): SELU()\n",
      "      (2): Dropout(p=0.25, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ARCHITECUTRE OptimizedModule(\n",
      "  (_orig_mod): CustomDuelingQNetworkWithIntentPrediction(\n",
      "    (shared_net): ModuleList(\n",
      "      (0): Linear(in_features=3149, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (action_input_net): ModuleList(\n",
      "      (0): Linear(in_features=783, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (value_net): ModuleList(\n",
      "      (0): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    )\n",
      "    (advantage_net): ModuleList(\n",
      "      (0): Linear(in_features=8192, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    )\n",
      "    (intent_head): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
      "      (1): SELU()\n",
      "      (2): Dropout(p=0.25, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Restoring weights...\n"
     ]
    }
   ],
   "source": [
    "model, state_encoding = load_model(ckpt_path=ckpt_path, cfg_name=cfg_name, device='cpu', data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_action(obs: dict) -> Tuple[int, bool]:\n",
    "    # encode observation\n",
    "    s = state_encoding.batch_encode(observation=[obs], sys_token=\"SYSTEM\", usr_token=\"USER\", sep_token=\"\") \n",
    "    # predict action & intent\n",
    "    action, intent = model.predict(observation=s, deterministic=True)\n",
    "    action = int(action)\n",
    "    intent = intent.item()\n",
    "\n",
    "    return action, intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What topic do you have questions about? You can either click on an answer from the suggested topics or enter your own text.\n",
      "  (policy: action 0, is faq: True)\n",
      "ASKING What topic do you have questions about? You can either click on an answer from the suggested topics or enter your own text.\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Are you going on an intracity trip or a business trip?\n",
      "  (done: False)\n",
      "  (policy: action 2, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Did you get verbal permission from your supervisor?\n",
      "  (done: False)\n",
      "  (policy: action 2, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Verbal permission is required from your supervisor for an intracity business trip. Please don't forg\n",
      "  (done: False)\n",
      "  (policy: action 0, is faq: True)\n",
      "ASKING Verbal permission is required from your supervisor for an intracity business trip. Please don't forget to get this. Written permission is not necessary\n",
      "  (done: False)\n",
      "  (policy: action 0, is faq: True)\n",
      "ASKING Verbal permission is required from your supervisor for an intracity business trip. Please don't forget to get this. Written permission is not necessary\n",
      "  (done: False)\n",
      "  (policy: action 0, is faq: True)\n",
      "ASKING Verbal permission is required from your supervisor for an intracity business trip. Please don't forget to get this. Written permission is not necessary\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Do you want to know more about booking Transportation or about ancillary costs?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO What type of transportation would you like?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Seat reservations are allowed for train travel\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Booking a first class train ticket is only allowed for distances of more than 100km.\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO You can book train tickets yourself (through the DB website, at their counter / ticket machine) or t\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Do you have any other questions about booking transportation?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO What type of transportation would you like?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Seat reservations are allowed for train travel\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Booking a first class train ticket is only allowed for distances of more than 100km.\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO You can book train tickets yourself (through the DB website, at their counter / ticket machine) or t\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Do you have any other questions about booking transportation?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO What type of transportation would you like?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Seat reservations are allowed for train travel\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Booking a first class train ticket is only allowed for distances of more than 100km.\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO You can book train tickets yourself (through the DB website, at their counter / ticket machine) or t\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Do you have any other questions about booking transportation?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO What type of transportation would you like?\n",
      "  (done: False)\n",
      "  (policy: action 1, is faq: True)\n",
      "SKIPPING\n",
      "-> TO Seat reservations are allowed for train travel\n",
      "  (done: False)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkornweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m done \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkornweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done \u001b[39mand\u001b[39;00m user_env\u001b[39m.\u001b[39mcurrent_user_utterance \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mexit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkornweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     action, intent \u001b[39m=\u001b[39m next_action(obs)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkornweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  (policy: action \u001b[39m\u001b[39m{\u001b[39;00maction\u001b[39m}\u001b[39;00m\u001b[39m, is faq: \u001b[39m\u001b[39m{\u001b[39;00mintent\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkornweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     obs, reward, done \u001b[39m=\u001b[39m user_env\u001b[39m.\u001b[39mstep(action\u001b[39m=\u001b[39maction)\n",
      "\u001b[1;32m/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkornweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnext_action\u001b[39m(obs: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mint\u001b[39m, \u001b[39mbool\u001b[39m]:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkornweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# encode observation\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkornweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     s \u001b[39m=\u001b[39m state_encoding\u001b[39m.\u001b[39;49mbatch_encode(observation\u001b[39m=\u001b[39;49m[obs], sys_token\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSYSTEM\u001b[39;49m\u001b[39m\"\u001b[39;49m, usr_token\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mUSER\u001b[39;49m\u001b[39m\"\u001b[39;49m, sep_token\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m) \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkornweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# predict action & intent\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkornweihe/mount/arbeitsdaten/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/realusertest.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     action, intent \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(observation\u001b[39m=\u001b[39ms, deterministic\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/mount/arbeitsdaten41/projekte/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/encoding/state.py:191\u001b[0m, in \u001b[0;36mStateEncoding.batch_encode\u001b[0;34m(self, observation, sys_token, usr_token, sep_token)\u001b[0m\n\u001b[1;32m    189\u001b[0m     state_encoding\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache\u001b[39m.\u001b[39mbatch_encode_text(state_input_key\u001b[39m=\u001b[39mState\u001b[39m.\u001b[39mNODE_TEXT, text\u001b[39m=\u001b[39m[node\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes]))\n\u001b[1;32m    190\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_config\u001b[39m.\u001b[39minitial_user_utterance \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_config\u001b[39m.\u001b[39minitial_user_utterance\u001b[39m.\u001b[39mactive:\n\u001b[0;32m--> 191\u001b[0m     state_encoding\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache\u001b[39m.\u001b[39;49mbatch_encode_text(state_input_key\u001b[39m=\u001b[39;49mState\u001b[39m.\u001b[39;49mINITIAL_USER_UTTERANCE, text\u001b[39m=\u001b[39;49m[obs[EnvInfo\u001b[39m.\u001b[39;49mINITIAL_USER_UTTERANCE] \u001b[39mfor\u001b[39;49;00m obs \u001b[39min\u001b[39;49;00m observation]))\n\u001b[1;32m    192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_config\u001b[39m.\u001b[39mdialog_history \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_config\u001b[39m.\u001b[39mdialog_history\u001b[39m.\u001b[39mactive:\n\u001b[1;32m    193\u001b[0m     dialog_history \u001b[39m=\u001b[39m [chain_dialog_history(sys_utterances\u001b[39m=\u001b[39mobs[EnvInfo\u001b[39m.\u001b[39mSYSTEM_UTTERANCE_HISTORY], usr_utterances\u001b[39m=\u001b[39mobs[EnvInfo\u001b[39m.\u001b[39mUSER_UTTERANCE_HISTORY],\n\u001b[1;32m    194\u001b[0m                                                     sys_token\u001b[39m=\u001b[39msys_token, usr_token\u001b[39m=\u001b[39musr_token, sep_token\u001b[39m=\u001b[39msep_token) \u001b[39mfor\u001b[39;00m obs \u001b[39min\u001b[39;00m observation]\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mount/arbeitsdaten41/projekte/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/data/cache.py:97\u001b[0m, in \u001b[0;36mCache.batch_encode_text\u001b[0;34m(self, state_input_key, text)\u001b[0m\n\u001b[1;32m     94\u001b[0m text_embedding: TextEmbeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_embeddings[text_embedding_name]\n\u001b[1;32m     96\u001b[0m \u001b[39m# embedding\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m embeddings \u001b[39m=\u001b[39m text_embedding\u001b[39m.\u001b[39;49mbatch_encode(text) \u001b[39m# batch x embedding_dim\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m# noise\u001b[39;00m\n\u001b[1;32m    100\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_noise(state_input_key\u001b[39m=\u001b[39mstate_input_key, embeddings\u001b[39m=\u001b[39membeddings)\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mount/arbeitsdaten41/projekte/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/encoding/text/base.py:57\u001b[0m, in \u001b[0;36mTextEmbeddings.batch_encode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbatch_encode\u001b[39m(\u001b[39mself\u001b[39m, text: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mFloatTensor, torch\u001b[39m.\u001b[39mFloatTensor]:\n\u001b[1;32m     52\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m        encodings: batch x max_length x embedding_size\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m        mask: batch x max_length (mask is 0 where padding occurs) or None, if not applicable\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode(text)\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mount/arbeitsdaten41/projekte/asr-2/vaethdk/cts_newcodebase_rollback/conversational-tree-search/encoding/text/sbert.py:41\u001b[0m, in \u001b[0;36mSentenceEmbeddings._batch_encode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_batch_encode\u001b[39m(\u001b[39mself\u001b[39m, text: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mFloatTensor]:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m        encodings: batch x 512\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m        mask: None (we don't need masks here since output is already pooled)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert_sentence_embedder\u001b[39m.\u001b[39;49mencode(text, convert_to_numpy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, convert_to_tensor\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:550\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    549\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids\u001b[39m=\u001b[39minput_ids, position_ids\u001b[39m=\u001b[39mposition_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds)\n\u001b[0;32m--> 550\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    551\u001b[0m     embedding_output,\n\u001b[1;32m    552\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    553\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    554\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    555\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    556\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    557\u001b[0m )\n\u001b[1;32m    558\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    559\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:339\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    337\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 339\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    340\u001b[0m     hidden_states,\n\u001b[1;32m    341\u001b[0m     attention_mask,\n\u001b[1;32m    342\u001b[0m     head_mask[i],\n\u001b[1;32m    343\u001b[0m     position_bias,\n\u001b[1;32m    344\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    345\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    346\u001b[0m )\n\u001b[1;32m    347\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    349\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:298\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    290\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    291\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    297\u001b[0m ):\n\u001b[0;32m--> 298\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    299\u001b[0m         hidden_states,\n\u001b[1;32m    300\u001b[0m         attention_mask,\n\u001b[1;32m    301\u001b[0m         head_mask,\n\u001b[1;32m    302\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    303\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    304\u001b[0m     )\n\u001b[1;32m    305\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    306\u001b[0m     outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:239\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    232\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    238\u001b[0m ):\n\u001b[0;32m--> 239\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[1;32m    240\u001b[0m         hidden_states,\n\u001b[1;32m    241\u001b[0m         attention_mask,\n\u001b[1;32m    242\u001b[0m         head_mask,\n\u001b[1;32m    243\u001b[0m         position_bias,\n\u001b[1;32m    244\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    245\u001b[0m     )\n\u001b[1;32m    246\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(self_outputs[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m hidden_states)\n\u001b[1;32m    247\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:166\u001b[0m, in \u001b[0;36mMPNetSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    158\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    159\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    165\u001b[0m ):\n\u001b[0;32m--> 166\u001b[0m     q \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq(hidden_states)\n\u001b[1;32m    167\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk(hidden_states)\n\u001b[1;32m    168\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv(hidden_states)\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/torch/nn/modules/linear.py:113\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    110\u001b[0m         bound \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(fan_in) \u001b[39mif\u001b[39;00m fan_in \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    111\u001b[0m         init\u001b[39m.\u001b[39muniform_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39m-\u001b[39mbound, bound)\n\u001b[0;32m--> 113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlinear(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextra_repr\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "obs = user_env.reset()\n",
    "done = False\n",
    "\n",
    "while not done and user_env.current_user_utterance != \"exit\":\n",
    "    action, intent = next_action(obs)\n",
    "    print(f\"  (policy: action {action}, is faq: {intent})\")\n",
    "    obs, reward, done = user_env.step(action=action)\n",
    "    print(f\"  (done: {done})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28479535-1$ ======== RESET =========',\n",
       " '28479535-1$ GOAL: 0 START',\n",
       " '28479535-1$ CONSTRAINTS:',\n",
       " '28479535-1$ INITIAL UTTERANCE: Can I bring my own car?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16460439592347465 - If you are at fault, costs cannot be reimbursed.',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16460439966919842 - If you are not at fault (e.g., a conference ran over), costs can be reimbursed if a suitable justifi',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16348058621438633 - What topic do you have questions about? You can either click on an answer from the suggested topics ',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16460439592347465 - If you are at fault, costs cannot be reimbursed.',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16460439966919842 - If you are not at fault (e.g., a conference ran over), costs can be reimbursed if a suitable justifi',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16348058621438633 - What topic do you have questions about? You can either click on an answer from the suggested topics ',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16460439592347465 - If you are at fault, costs cannot be reimbursed.',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16460439966919842 - If you are not at fault (e.g., a conference ran over), costs can be reimbursed if a suitable justifi',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16348058621438633 - What topic do you have questions about? You can either click on an answer from the suggested topics ',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16460439592347465 - If you are at fault, costs cannot be reimbursed.',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16460439966919842 - If you are not at fault (e.g., a conference ran over), costs can be reimbursed if a suitable justifi',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16348058621438633 - What topic do you have questions about? You can either click on an answer from the suggested topics ',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16370679473901470 - What do I do in an emergency on a business trip? Please call the number listed on the Emergency-Card',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16384313191857195 - Do you have any further questions?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16348058621438633 - What topic do you have questions about? You can either click on an answer from the suggested topics ',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16370679473901470 - What do I do in an emergency on a business trip? Please call the number listed on the Emergency-Card',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16384313191857195 - Do you have any further questions?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16348058621438633 - What topic do you have questions about? You can either click on an answer from the suggested topics ',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16370679473901470 - What do I do in an emergency on a business trip? Please call the number listed on the Emergency-Card',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16384313191857195 - Do you have any further questions?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16348058621438633 - What topic do you have questions about? You can either click on an answer from the suggested topics ',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16370679473901470 - What do I do in an emergency on a business trip? Please call the number listed on the Emergency-Card',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16384313191857195 - Do you have any further questions?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16348058621438633 - What topic do you have questions about? You can either click on an answer from the suggested topics ',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16370679473901470 - What do I do in an emergency on a business trip? Please call the number listed on the Emergency-Card',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16384313191857195 - Do you have any further questions?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16348058621438633 - What topic do you have questions about? You can either click on an answer from the suggested topics ',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16370679473901470 - What do I do in an emergency on a business trip? Please call the number listed on the Emergency-Card',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16384313191857195 - Do you have any further questions?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16348058621438633 - What topic do you have questions about? You can either click on an answer from the suggested topics ',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16370679473901470 - What do I do in an emergency on a business trip? Please call the number listed on the Emergency-Card',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16384313191857195 - Do you have any further questions?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16348058621438633 - What topic do you have questions about? You can either click on an answer from the suggested topics ',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: infoNode - 16370679473901470 - What do I do in an emergency on a business trip? Please call the number listed on the Emergency-Card',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16384313191857195 - Do you have any further questions?',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16348058621438633 - What topic do you have questions about? You can either click on an answer from the suggested topics ',\n",
       " '28479535-1$ -> TURN REWARD: -1.0',\n",
       " '28479535-1$ -> USER UTTERANCE: ',\n",
       " '28479535-1$ TO NODE: userResponseNode - 16460436532310883 - What emergency are you experiencing?',\n",
       " '28479535-1$ REACHED MAX LENGTH',\n",
       " '28479535-1$ => REACHED GOAL ONCE: False',\n",
       " '28479535-1$ => ASKED GOAL ONCE: False',\n",
       " '28479535-1$ => FINAL REWARD: -49.0',\n",
       " '28479535-1$ => PERCIEVED LENGTH: 1',\n",
       " '28479535-1$ => TOTAL LENGTH: 49']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_env.current_episode_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cts_en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
