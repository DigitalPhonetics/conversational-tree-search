{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Statistics =====\n",
      "- files:  en/reimburse/train_graph.json en/reimburse/train_answers.json\n",
      "- synonyms: True\n",
      "- depth: 20  - degree: 13\n",
      "- answers: 312\n",
      "- questions: 279\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n",
      "- question limit: 0  - maximum loaded:  7\n",
      "- answer limit: 0  - maximum loaded:  9\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from copy import deepcopy\n",
    "from data.dataset import ReimburseGraphDataset, DataAugmentationLevel, DialogNode, NodeType\n",
    "from environment.goal import GoalPath, VariableValue, Condition\n",
    "from data.parsers.answerTemplateParser import AnswerTemplateParser\n",
    "\n",
    "data_human = ReimburseGraphDataset('en/reimburse/train_graph.json', 'en/reimburse/train_answers.json', True, augmentation=DataAugmentationLevel.NONE, augmentation_path=None, resource_dir=\"./resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate amount of hard goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_path(goal_node: DialogNode, start_node: DialogNode, answerParser: AnswerTemplateParser):\n",
    "    active_paths: List[GoalPath] = [GoalPath(current_node=start_node, visited_nodes=[], visited_ids=set(), chosen_answers={}, constraints={})]\n",
    "    valid_paths: List[GoalPath] = []\n",
    "\n",
    "    while len(active_paths) > 0:\n",
    "        # expand current level\n",
    "        path = active_paths.pop(0)\n",
    "        current_node = path.current_node\n",
    "\n",
    "        # expand constraints if current node is variable node\n",
    "        next_constraints = path.constraints.copy()\n",
    "        next_visited_ids = path.visited_ids.union([current_node.key])\n",
    "        next_visited_nodes = path.visited_nodes.copy() + [current_node]\n",
    "\n",
    "        if current_node.node_type == NodeType.VARIABLE:\n",
    "            assert len(current_node.answers) == 1, \"Should have exactly 1 answer\"\n",
    "            variable = answerParser.find_variable(current_node.answer_by_index(0).text)\n",
    "            if not variable.name in next_constraints:\n",
    "                next_constraints[variable.name] = VariableValue(var_name=variable.name, var_type=variable.type)\n",
    "\n",
    "        if current_node.key == goal_node.key:\n",
    "            # we reached the goal node -> save path\n",
    "            valid_paths.append(GoalPath(current_node=current_node,\n",
    "                                        visited_nodes=next_visited_nodes,\n",
    "                                        chosen_answers=path.chosen_answers,\n",
    "                                        constraints=next_constraints,\n",
    "                                        visited_ids=next_visited_ids))\n",
    "        else:\n",
    "            # extend path by visiting all neighbours of current node\n",
    "            if current_node.connected_node and not (current_node.connected_node.key in path.visited_ids):\n",
    "                # variable node or info node\n",
    "                active_paths.append(GoalPath(current_node=current_node.connected_node,\n",
    "                                            visited_nodes=next_visited_nodes,\n",
    "                                            chosen_answers=path.chosen_answers,\n",
    "                                            constraints=next_constraints,\n",
    "                                            visited_ids=next_visited_ids))\n",
    "            elif len(current_node.answers) > 0:\n",
    "                # question node or logic node\n",
    "\n",
    "                # collect all conditions, find default condition\n",
    "                conditions: List[Condition] = []\n",
    "                if current_node.node_type == NodeType.LOGIC:\n",
    "                    for condition in current_node.answers:\n",
    "                        var_name, op, var_value = f\"{current_node.text.replace('{{', '')} {condition.text.replace('}}', '')}\".split()\n",
    "                        assert var_name in next_constraints, f\"Logic node for {var_name} on path wihtout preceeding variable node!\"\n",
    "                        conditions.append(Condition(var_name=var_name, op=op, \n",
    "                                                    var_value=var_value.strip().replace('\"', ''),\n",
    "                                                    default=var_value == \"DEFAULT\"))\n",
    "                \n",
    "                # create new paths for each answer\n",
    "                for answer_idx, answer in enumerate(current_node.answers):\n",
    "                    # visit neighbour (with loop breaker)\n",
    "                    if answer.connected_node and not (answer.connected_node.key in path.visited_ids):\n",
    "                        final_constraints = next_constraints\n",
    "                        if current_node.node_type == NodeType.LOGIC:\n",
    "                            final_constraints = deepcopy(next_constraints)\n",
    "                            condition = conditions[answer_idx]\n",
    "                            if condition.default == True:\n",
    "                                compatible = final_constraints[condition.var_name].add_default_condition([(other_cond.op, other_cond.var_value) for other_cond in conditions if not other_cond.default])\n",
    "                            else:\n",
    "                                compatible = final_constraints[condition.var_name].add_condition(condition.op, condition.var_value)\n",
    "                            if not compatible:\n",
    "                                continue # prune impossible path       \n",
    "                        next_chosen_answers = path.chosen_answers.copy()\n",
    "                        next_chosen_answers[current_node.key] = answer\n",
    "                        active_paths.append(GoalPath(current_node=answer.connected_node,\n",
    "                                            visited_nodes=next_visited_nodes,\n",
    "                                            chosen_answers=next_chosen_answers,\n",
    "                                            constraints=final_constraints,\n",
    "                                            visited_ids=next_visited_ids))\n",
    "\n",
    "    return valid_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialogNode.QUESTION(key: 16348058621438633, answers: 6, questions: 0)\n",
      "        - connected_node: None\n",
      "        - text: What topic do you have questions about? You can either click on an answer from the suggested topics \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "start_node = data_human.start_node.connected_node\n",
    "print(start_node)\n",
    "answerParser = AnswerTemplateParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard goals: 35\n",
      "Total goals: 80\n",
      "Hard goal ratio: 0.4375\n"
     ]
    }
   ],
   "source": [
    "hard_goal_nodes = set()\n",
    "\n",
    "for goal_node in data_human.nodes_by_type[NodeType.INFO]:\n",
    "    # calculate all possible paths to node\n",
    "    paths = expand_path(goal_node, start_node, answerParser)\n",
    "\n",
    "    # check if each path contains either\n",
    "    # a) a template node\n",
    "    # b) a logic node\n",
    "    all_paths_need_variables = True\n",
    "    for path in paths:\n",
    "        needs_variable = False\n",
    "        for node in path.visited_nodes:\n",
    "            if \"{{\" in node.text:\n",
    "                # condition a)\n",
    "                needs_variable = True\n",
    "                break\n",
    "            if node.node_type == NodeType.LOGIC:\n",
    "                # condition b)\n",
    "                needs_variable = True\n",
    "                break\n",
    "        if not needs_variable:\n",
    "            all_paths_need_variables = False\n",
    "            break\n",
    "    \n",
    "    if all_paths_need_variables:\n",
    "        hard_goal_nodes.add(goal_node.key)\n",
    "\n",
    "print(\"Hard goals:\", len(hard_goal_nodes))\n",
    "print(\"Total goals:\", len(data_human.nodes_by_type[NodeType.INFO]))\n",
    "print(\"Hard goal ratio:\", len(hard_goal_nodes)/len(data_human.nodes_by_type[NodeType.INFO]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes, Tree Depth, Questions, Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Statistics =====\n",
      "- files:  en/reimburse/train_graph.json en/reimburse/train_answers.json\n",
      "- synonyms: True\n",
      "- depth: 20  - degree: 13\n",
      "- answers: 248\n",
      "- questions: 279\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n",
      "- question limit: 0  - maximum loaded:  7\n",
      "- answer limit: 0  - maximum loaded:  9\n",
      "#Nodes: 123\n",
      "Avg questions / info node: 3.4875\n",
      "Avg answers / question node: 3.3972602739726026\n"
     ]
    }
   ],
   "source": [
    "data_human_train_en = ReimburseGraphDataset('en/reimburse/train_graph.json', 'en/reimburse/train_answers.json', True, augmentation=DataAugmentationLevel.NONE, augmentation_path=None, resource_dir=\"./resources\")\n",
    "\n",
    "print(\"#Nodes:\", len(data_human_train_en.node_list))\n",
    "print(\"Avg questions / info node:\",  len(data_human_train_en.question_list) / len(data_human_train_en.nodes_by_type[NodeType.INFO]) )\n",
    "print(\"Avg answers / question node:\", sum([len(data_human_train_en.answer_synonyms[ans]) for ans in data_human_train_en.answer_synonyms ]) / len(data_human_train_en.answer_synonyms) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Statistics =====\n",
      "- files:  en/reimburse/test_graph.json en/reimburse/test_answers.json\n",
      "- synonyms: True\n",
      "- depth: 20  - degree: 13\n",
      "- answers: 162\n",
      "- questions: 173\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n",
      "- question limit: 0  - maximum loaded:  4\n",
      "- answer limit: 0  - maximum loaded:  4\n",
      "#Nodes: 123\n",
      "Avg questions / info node: 2.1625\n",
      "Avg answers / question node: 2.219178082191781\n"
     ]
    }
   ],
   "source": [
    "data_human_test_en = ReimburseGraphDataset('en/reimburse/test_graph.json', 'en/reimburse/test_answers.json', True, augmentation=DataAugmentationLevel.NONE, augmentation_path=None, resource_dir=\"./resources\")\n",
    "\n",
    "print(\"#Nodes:\", len(data_human_test_en.node_list))\n",
    "print(\"Avg questions / info node:\",  len(data_human_test_en.question_list) / len(data_human_test_en.nodes_by_type[NodeType.INFO]) )\n",
    "print(\"Avg answers / question node:\", sum([len(data_human_test_en.answer_synonyms[ans]) for ans in data_human_test_en.answer_synonyms ]) / len(data_human_test_en.answer_synonyms) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Statistics =====\n",
      "- files:  de/reimburse/train_graph.json de/reimburse/train_answers.json\n",
      "- synonyms: True\n",
      "- depth: 20  - degree: 13\n",
      "- answers: 246\n",
      "- questions: 279\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n",
      "- question limit: 0  - maximum loaded:  7\n",
      "- answer limit: 0  - maximum loaded:  9\n",
      "#Nodes: 123\n",
      "Avg questions / info node: 3.5316455696202533\n",
      "Avg answers / question node: 3.3698630136986303\n"
     ]
    }
   ],
   "source": [
    "data_human_train_de = ReimburseGraphDataset('de/reimburse/train_graph.json', 'de/reimburse/train_answers.json', True, augmentation=DataAugmentationLevel.NONE, augmentation_path=None, resource_dir=\"./resources\")\n",
    "\n",
    "\n",
    "print(\"#Nodes:\", len(data_human_train_de.node_list))\n",
    "print(\"Avg questions / info node:\",  len(data_human_train_de.question_list) / len(data_human_train_de.nodes_by_type[NodeType.INFO]) )\n",
    "print(\"Avg answers / question node:\", sum([len(data_human_train_de.answer_synonyms[ans]) for ans in data_human_train_de.answer_synonyms ]) / len(data_human_train_de.answer_synonyms) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Statistics =====\n",
      "- files:  de/reimburse/test_graph.json de/reimburse/test_answers.json\n",
      "- synonyms: True\n",
      "- depth: 20  - degree: 13\n",
      "- answers: 162\n",
      "- questions: 173\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n",
      "- question limit: 0  - maximum loaded:  4\n",
      "- answer limit: 0  - maximum loaded:  4\n",
      "#Nodes: 123\n",
      "Avg questions / info node: 2.189873417721519\n",
      "Avg answers / question node: 2.219178082191781\n"
     ]
    }
   ],
   "source": [
    "data_human_test_de = ReimburseGraphDataset('de/reimburse/test_graph.json', 'de/reimburse/test_answers.json', True, augmentation=DataAugmentationLevel.NONE, augmentation_path=None, resource_dir=\"./resources\")\n",
    "\n",
    "\n",
    "print(\"#Nodes:\", len(data_human_test_de.node_list))\n",
    "print(\"Avg questions / info node:\",  len(data_human_test_de.question_list) / len(data_human_test_de.nodes_by_type[NodeType.INFO]) )\n",
    "print(\"Avg answers / question node:\", sum([len(data_human_test_de.answer_synonyms[ans]) for ans in data_human_test_de.answer_synonyms ]) / len(data_human_test_de.answer_synonyms) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Statistics =====\n",
      "- files:  en/onboarding/train_graph.json en/onboarding/train_answers.json\n",
      "- synonyms: True\n",
      "- depth: 12  - degree: 9\n",
      "- answers: 175\n",
      "- questions: 141\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n",
      "- question limit: 0  - maximum loaded:  4\n",
      "- answer limit: 0  - maximum loaded:  4\n",
      "#Nodes 88\n",
      "#Answers (we don't have synonyms):  175\n",
      "Avg questions / info node: 2.389830508474576\n",
      "Avg answers / question node: 3.0701754385964914\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from data.dataset import StandardGraphDataset\n",
    "\n",
    "\n",
    "data_onboard = GraphDataset('en/onboarding/train_graph.json', 'en/onboarding/train_answers.json', True, DataAugmentationLevel.NONE, augmentation_path=None, resource_dir='./resources')\n",
    "\n",
    "print(\"#Nodes\", len(data_onboard.node_list))\n",
    "print(\"#Answers (we don't have synonyms): \", sum([len(data_onboard.answer_synonyms[ans]) for ans in data_onboard.answer_synonyms ]))\n",
    "print(\"Avg questions / info node:\",  len(data_onboard.question_list) / len(data_onboard.nodes_by_type[NodeType.INFO]) )\n",
    "print(\"Avg answers / question node:\", sum([len(data_onboard.answer_synonyms[ans]) for ans in data_onboard.answer_synonyms ]) / len(data_onboard.answer_synonyms) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Statistics =====\n",
      "- files:  en/onboarding/test_graph.json en/onboarding/test_answers.json\n",
      "- synonyms: True\n",
      "- depth: 12  - degree: 9\n",
      "- answers: 152\n",
      "- questions: 117\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n",
      "- question limit: 0  - maximum loaded:  3\n",
      "- answer limit: 0  - maximum loaded:  4\n",
      "#Nodes 88\n",
      "#Answers (we don't have synonyms):  152\n",
      "Avg questions / info node: 1.9830508474576272\n",
      "Avg answers / question node: 2.6666666666666665\n"
     ]
    }
   ],
   "source": [
    "# CHECK TRAIN-TEST GRA\n",
    "from data.dataset import StandardGraphDataset, GraphDataset\n",
    "\n",
    "\n",
    "data_onboard = GraphDataset('en/onboarding/test_graph.json', 'en/onboarding/test_answers.json', True, DataAugmentationLevel.NONE, augmentation_path=None, resource_dir='./resources')\n",
    "\n",
    "print(\"#Nodes\", len(data_onboard.node_list))\n",
    "print(\"#Answers (we don't have synonyms): \", sum([len(data_onboard.answer_synonyms[ans]) for ans in data_onboard.answer_synonyms ]))\n",
    "print(\"Avg questions / info node:\",  len(data_onboard.question_list) / len(data_onboard.nodes_by_type[NodeType.INFO]) )\n",
    "print(\"Avg answers / question node:\", sum([len(data_onboard.answer_synonyms[ans]) for ans in data_onboard.answer_synonyms ]) / len(data_onboard.answer_synonyms) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIAGNOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Statistics =====\n",
      "- files:  en/diagnose/train_graph.json en/diagnose/train_answers.json\n",
      "- synonyms: True\n",
      "- depth: 9  - degree: 6\n",
      "- answers: 298\n",
      "- questions: 219\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n",
      "- question limit: 0  - maximum loaded:  3\n",
      "- answer limit: 0  - maximum loaded:  3\n",
      "#Nodes 98\n",
      "#Answers (we don't have synonyms):  298\n",
      "Avg questions / info node: 2.92\n",
      "Avg answers / question node: 2.98\n"
     ]
    }
   ],
   "source": [
    "data_onboard = GraphDataset('en/diagnose/train_graph.json', 'en/diagnose/train_answers.json', True, DataAugmentationLevel.NONE, augmentation_path=None, resource_dir='./resources')\n",
    "\n",
    "print(\"#Nodes\", len(data_onboard.node_list))\n",
    "print(\"#Answers (we don't have synonyms): \", sum([len(data_onboard.answer_synonyms[ans]) for ans in data_onboard.answer_synonyms ]))\n",
    "print(\"Avg questions / info node:\",  len(data_onboard.question_list) / len(data_onboard.nodes_by_type[NodeType.INFO]) )\n",
    "print(\"Avg answers / question node:\", sum([len(data_onboard.answer_synonyms[ans]) for ans in data_onboard.answer_synonyms ]) / len(data_onboard.answer_synonyms) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Statistics =====\n",
      "- files:  en/diagnose/test_graph.json en/diagnose/test_answers.json\n",
      "- synonyms: True\n",
      "- depth: 9  - degree: 6\n",
      "- answers: 298\n",
      "- questions: 150\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n",
      "- question limit: 0  - maximum loaded:  3\n",
      "- answer limit: 0  - maximum loaded:  3\n",
      "#Nodes 98\n",
      "#Answers (we don't have synonyms):  298\n",
      "Avg questions / info node: 2.0\n",
      "Avg answers / question node: 2.98\n"
     ]
    }
   ],
   "source": [
    "data_onboard = GraphDataset('en/diagnose/test_graph.json', 'en/diagnose/test_answers.json', True, DataAugmentationLevel.NONE, augmentation_path=None, resource_dir='./resources')\n",
    "\n",
    "print(\"#Nodes\", len(data_onboard.node_list))\n",
    "print(\"#Answers (we don't have synonyms): \", sum([len(data_onboard.answer_synonyms[ans]) for ans in data_onboard.answer_synonyms ]))\n",
    "print(\"Avg questions / info node:\",  len(data_onboard.question_list) / len(data_onboard.nodes_by_type[NodeType.INFO]) )\n",
    "print(\"Avg answers / question node:\", sum([len(data_onboard.answer_synonyms[ans]) for ans in data_onboard.answer_synonyms ]) / len(data_onboard.answer_synonyms) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cts_en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
