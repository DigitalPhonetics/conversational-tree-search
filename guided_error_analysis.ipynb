{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda:0'\n",
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load base text encoding\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "sbert = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=DEVICE, cache_folder = \"/mount/arbeitsdaten/asr-2/vaethdk/resources/weights\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Statistics =====\n",
      "- files:  en/reimburse/train_graph.json en/reimburse/train_answers.json\n",
      "- synonyms: True\n",
      "- depth: 20  - degree: 13\n",
      "- answers: 248\n",
      "- questions: 279\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n",
      "===== Dataset Statistics =====\n",
      "- files:  en/reimburse/test_graph.json en/reimburse/test_answers.json\n",
      "- synonyms: True\n",
      "- depth: 20  - degree: 13\n",
      "- answers: 162\n",
      "- questions: 173\n",
      "- loaded original data: True\n",
      "- loaded generated data: False\n",
      "- Loading questions from  ./resources/en/reimburse/generated/train_questions_v1.json\n",
      "- only artificial answers\n",
      "Loading augmentation answers from ./resources/en/reimburse/generated/train_answers.json\n",
      "===== Dataset Statistics =====\n",
      "- files:  en/reimburse/train_graph.json en/reimburse/train_answers.json\n",
      "- synonyms: True\n",
      "- depth: 20  - degree: 13\n",
      "- answers: 803\n",
      "- questions: 800\n",
      "- loaded original data: False\n",
      "- loaded generated data: True\n",
      "- Loading questions from  ./resources/en/reimburse/generated/train_questions_v2.json\n",
      "- only artificial answers\n",
      "Loading augmentation answers from ./resources/en/reimburse/generated/train_answers.json\n",
      "===== Dataset Statistics =====\n",
      "- files:  en/reimburse/train_graph.json en/reimburse/train_answers.json\n",
      "- synonyms: True\n",
      "- depth: 20  - degree: 13\n",
      "- answers: 803\n",
      "- questions: 800\n",
      "- loaded original data: False\n",
      "- loaded generated data: True\n",
      "- Loading questions from  ./resources/en/reimburse/generated/train_questions_v3.json\n",
      "- only artificial answers\n",
      "Loading augmentation answers from ./resources/en/reimburse/generated/train_answers.json\n",
      "===== Dataset Statistics =====\n",
      "- files:  en/reimburse/train_graph.json en/reimburse/train_answers.json\n",
      "- synonyms: True\n",
      "- depth: 20  - degree: 13\n",
      "- answers: 803\n",
      "- questions: 416\n",
      "- loaded original data: False\n",
      "- loaded generated data: True\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "from data.dataset import DataAugmentationLevel, ReimburseGraphDataset, NodeType\n",
    "\n",
    "\n",
    "human_data_train = ReimburseGraphDataset('en/reimburse/train_graph.json', 'en/reimburse/train_answers.json', True, augmentation=DataAugmentationLevel.NONE, resource_dir=\"./resources/\")\n",
    "human_data_test = ReimburseGraphDataset('en/reimburse/test_graph.json', 'en/reimburse/test_answers.json', True, augmentation=DataAugmentationLevel.NONE, resource_dir=\"./resources/\")\n",
    "generated_data_train_v1 = ReimburseGraphDataset('en/reimburse/train_graph.json', 'en/reimburse/train_answers.json', True, augmentation=DataAugmentationLevel.ARTIFICIAL_ONLY, augmentation_path=\"en/reimburse/generated/train_questions_v1.json\", resource_dir=\"./resources/\")\n",
    "generated_data_train_v2 = ReimburseGraphDataset('en/reimburse/train_graph.json', 'en/reimburse/train_answers.json', True, augmentation=DataAugmentationLevel.ARTIFICIAL_ONLY, augmentation_path=\"en/reimburse/generated/train_questions_v2.json\", resource_dir=\"./resources/\")\n",
    "generated_data_train_v3 = ReimburseGraphDataset('en/reimburse/train_graph.json', 'en/reimburse/train_answers.json', True, augmentation=DataAugmentationLevel.ARTIFICIAL_ONLY, augmentation_path=\"en/reimburse/generated/train_questions_v3.json\", resource_dir=\"./resources/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Human Train\": human_data_train,\n",
    "    \"Human Test\": human_data_test,\n",
    "    \"Generated V1\": generated_data_train_v1,\n",
    "    \"Generated V2\": generated_data_train_v2,\n",
    "    \"Generated V3\": generated_data_train_v3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Human Train': 0.9429657794676806, 'Human Test': 0.9378531073446328, 'Generated V1': 0.9420454545454545, 'Generated V2': 0.9420454545454545, 'Generated V3': 0.9420454545454545}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### Test per-node similarity top-1 accuracy of base similarity model\n",
    "###\n",
    "from tqdm.auto import tqdm\n",
    "from statistics import mean\n",
    "\n",
    "ds_accuracies = {} # accuracy accross datasets\n",
    "for ds_name, ds in tqdm(datasets.items()):\n",
    "    ds_accuracies[ds_name] = []\n",
    "    for node in ds.nodes_by_type[NodeType.QUESTION]:\n",
    "        # encode node answers\n",
    "        num_answers = len(node.answers)\n",
    "        if num_answers < 2: # comparison only interesting if there is at least a single choice to be made (>= 2 answers)\n",
    "            continue\n",
    "\n",
    "        answer_candidate_enc = sbert.encode([answer_candidate.text for answer_candidate in node.answers], device=DEVICE, convert_to_tensor=True) # encode answer candidates\n",
    "        # print(\"ANSWERS\", [answer_candidate.text for answer_candidate in node.answers])\n",
    "        # print(\"CAND SHAPE\", answer_candidate_enc.size())\n",
    "        for answer_candidate_idx, answer_candidate in enumerate(node.answers):\n",
    "            # print(\"CANDIDATE\", answer_candidate.text)\n",
    "            # print(\"SYNONYMS\", ds.answer_synonyms[answer_candidate.text.lower()])\n",
    "            answer_synonym_enc = sbert.encode(ds.answer_synonyms[answer_candidate.text.lower()], device=DEVICE, convert_to_tensor=True) # encode synonyms\n",
    "            # print(\"SYNONYM SHAPE\", answer_synonym_enc.size())\n",
    "            cosine_scores = util.cos_sim(answer_synonym_enc, answer_candidate_enc) # calculate similarity beween candidate and synonyms (candidates are columns, synonyms are rows)\n",
    "            # print(\"SIMILARITY SHAPE\", cosine_scores.size())\n",
    "            # print(cosine_scores)\n",
    "            # print(\"MOST SIMILAR ANSWERS\")\n",
    "            most_similar_candidates = cosine_scores.argmax(dim=-1)\n",
    "            # print(most_similar_candidates)\n",
    "            accuracies = (most_similar_candidates == answer_candidate_idx).float().tolist()\n",
    "            # print(accuracies)\n",
    "            ds_accuracies[ds_name].extend(accuracies)\n",
    "        # break\n",
    "    # break\n",
    "\n",
    "    ds_accuracies[ds_name] = mean(ds_accuracies[ds_name])\n",
    "print(ds_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cts_en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
