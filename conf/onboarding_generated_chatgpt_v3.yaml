defaults:
  - config_schema
  # overwrite defaults loaded above with the following content from this file
  # dataset choice: train, test, joint (train + test)
  
  # model, algorithm & optimizer
  - optimizer@experiment.optimizer: adam
  - net_arch@experiment.policy.net_arch: dqn/decoupled_dueling_dqn_with_intentprediction
  - algorithm@experiment.algorithm: dqn/dqn
  - algorithm/dqn/targets@experiment.algorithm.dqn.targets: muenchausen

  # embeddings
  - embeddings/text/model@experiment.state.node_text: mpnet_base
  - embeddings/text/model@experiment.state.initial_user_utterance: mpnet_base
  - embeddings/text/model@experiment.state.current_user_utterance: mpnet_base
  - embeddings/text/model@experiment.state.action_text: mpnet_base
  - embeddings/text/model@experiment.state.dialog_history: mpnet_base
  - _self_
hydra:
  run:
    dir: ${run_dir:}
experiment:
  _target_: training.trainer.Trainer
  device: cuda:0
  seed: 12345678
  torch_compile: true
  cudnn_deterministic: false
  optimizer:
    class_path: torch.optim.Adam
    lr: 0.0001
  policy:
    _target_: algorithm.dqn.dqn.CustomDQNPolicy
    activation_fn: torch.nn.SELU
    net_arch:
      net_cls: algorithm.dqn.architecture.CustomDuelingQNetworkWithIntentPrediction
      shared_layer_sizes:
      - 4096
      - 4096
      - 4096
      value_layer_sizes:
      - 2048
      - 1024
      advantage_layer_sizes:
      - 4096
      - 2048
      - 1024
      dropout_rate: 0.25
      normalization_layers: false
      intent_loss_weight: 0.1
      q_value_clipping: 10.0
  algorithm:
    dqn:
      targets:
        _target_: algorithm.dqn.targets.MuenchausenTarget
        tau: 0.03
        alpha: 0.9
        clipping: -1.0
      buffer:
        backend:
          _target_: data.buffers.dqn.prioritized.PrioritizedReplayBuffer
          buffer_size: 100000
          device: cpu
          alpha: 0.6
          beta: 0.4
          use_lap: false
      _target_: algorithm.dqn.dqn.DQNAlgorithm
      timesteps_per_reset: 2000000
      reset_exploration_times: 0
      max_grad_norm: 1.0
      batch_size: 256
      gamma: 0.99
      exploration_fraction: 0.99
      eps_start: 0.9
      eps_end: 0.0
      warmup_turns: 2560
      target_network_update_frequency: 2
      q_value_clipping: 10.0
      save_terminal_obs: true
  logging:
    dialog_log: DialogLogLevel.FULL
    wandb_log: WandbLogLevel.ONLINE
    log_interval: 1000
    keep_checkpoints: 5
  environment:
    guided_free_ratio: 0.5
    auto_skip: AutoSkipMode.NONE
    normalize_rewards: true
    max_steps: 50
    user_patience: 3
    stop_when_reaching_goal: true
    stop_on_invalid_skip: false
    num_train_envs: 256
    num_val_envs: 100
    num_test_envs: 100
    goal_distance_mode: GoalDistanceMode.FULL_DISTANCE
    goal_distance_increment: 100
    sys_token: 'SYSTEM:'
    usr_token: 'USER:'
    sep_token: ''
  actions:
    in_state_space: true
    action_masking: true
  state:
    last_system_action: true
    beliefstate: true
    node_position: true
    node_type: true
    action_position: true
    node_text:
      active: true
      pooling: TextEmbeddingPooling.NONE
      noise_std: 0.0
      caching: false
      ckpt_name: sentence-transformers/all-mpnet-base-v2
      embedding_dim: 768
      _target_: encoding.text.sbert.SentenceEmbeddings
    dialog_history:
      active: true
      pooling: TextEmbeddingPooling.NONE
      noise_std: 0.0
      caching: false
      ckpt_name: sentence-transformers/all-mpnet-base-v2
      embedding_dim: 768
      _target_: encoding.text.sbert.SentenceEmbeddings
    action_text:
      active: true
      pooling: TextEmbeddingPooling.NONE
      noise_std: 0.0
      caching: false
      ckpt_name: sentence-transformers/all-mpnet-base-v2
      embedding_dim: 768
      _target_: encoding.text.sbert.SentenceEmbeddings
    current_user_utterance:
      active: true
      pooling: TextEmbeddingPooling.NONE
      noise_std: 1.0
      caching: false
      ckpt_name: sentence-transformers/all-mpnet-base-v2
      embedding_dim: 768
      _target_: encoding.text.sbert.SentenceEmbeddings
    initial_user_utterance:
      active: true
      pooling: TextEmbeddingPooling.NONE
      noise_std: 1.0
      caching: false
      ckpt_name: sentence-transformers/all-mpnet-base-v2
      embedding_dim: 768
      _target_: encoding.text.sbert.SentenceEmbeddings
  training:
    dataset:
      _target_: data.dataset.StandardGraphDataset
      graph_path: en/onboarding/train_graph.json
      answer_path: en/onboarding/train_answers.json
      use_answer_synonyms: true
      augmentation: DataAugmentationLevel.ARTIFICIAL_ONLY
      augmentation_path: en/onboarding/generated/chatgpt/train_questions_v3.json
      question_limit: 0
      answer_limit: 0
      language: en
    every_steps: 3
    noise: 0.1
  validation:
    dataset:
      _target_: data.dataset.StandardGraphDataset
      graph_path: en/onboarding/train_graph.json
      answer_path: en/onboarding/train_answers.json
      use_answer_synonyms: true
      augmentation: DataAugmentationLevel.ARTIFICIAL_ONLY
      augmentation_path: en/onboarding/generated/chatgpt/train_questions_v3.json
      question_limit: 0
      answer_limit: 0
      language: en
    every_steps: 15000
    noise: 0.0
    dialogs: 500
  testing:
    dataset:
      _target_: data.dataset.GraphDataset
      graph_path: en/onboarding/test_graph.json
      answer_path: en/onboarding/test_answers.json
      use_answer_synonyms: true
      augmentation: DataAugmentationLevel.NONE
      question_limit: 0
      answer_limit: 0
      language: en
    every_steps: 15000
    noise: 0.0
    dialogs: 500