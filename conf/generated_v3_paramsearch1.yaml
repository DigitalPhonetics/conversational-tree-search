defaults:
  - config_schema
  # dataset choice: train, test, joint (train + test)
  - dataset@experiment.training.dataset : train
  - dataset@experiment.validation.dataset: train
  - dataset@experiment.testing.dataset: test
  
  # model, algorithm & optimizer
  - optimizer@experiment.optimizer: adam
  - net_arch@experiment.policy.net_arch: dqn/decoupled_dueling_dqn_with_intentprediction
  - algorithm@experiment.algorithm: dqn/dqn
  - algorithm/dqn/targets@experiment.algorithm.dqn.targets: muenchausen

  # embeddings
  - embeddings/text/model@experiment.state.node_text: mpnet_base
  - embeddings/text/model@experiment.state.initial_user_utterance: mpnet_base
  - embeddings/text/model@experiment.state.current_user_utterance: mpnet_base
  - embeddings/text/model@experiment.state.action_text: mpnet_base
  - embeddings/text/model@experiment.state.dialog_history: mpnet_base

  # overwrite defaults loaded above with the following content from this file
  - _self_

hydra:
  run:
    dir: ${run_dir:}
experiment:
  device: cuda:0
  seed: 12345678
  cudnn_deterministic: false
  torch_compile: true
  logging:
    keep_checkpoints: 5
    wandb_log: ONLINE
    dialog_log: FULL
    log_interval: 1000
  training:
    noise: 0.1
    every_steps: 1
    dataset:
      use_answer_synonyms: true
      augmentation: ARTIFICIAL_ONLY
      augmentation_version: 3
  validation:
    noise: 0.0
    every_steps: 15000
    dialogs: 500
    dataset:
      use_answer_synonyms: true
      augmentation: ARTIFICIAL_ONLY
      augmentation_version: 3
  testing:
    noise: 0.0
    every_steps: 15000
    dialogs: 500
    dataset:
      use_answer_synonyms: true
      augmentation: NONE
      augmentation_version: 0
  policy:
    _target_: algorithm.dqn.dqn.CustomDQNPolicy
    activation_fn: torch.nn.SELU
    net_arch:
      shared_layer_sizes:
      - 4096
      - 4096
      - 4096
      value_layer_sizes:
      - 2048
      - 1024
      - 1024
      advantage_layer_sizes:
      - 4096
      - 2048
      - 1024
      dropout_rate: 0.1
      normalization_layers: true
      intent_loss_weight: 0.1
      q_value_clipping: 10.0
  optimizer:
    class_path: torch.optim.Adam
    scheduler:
      start_lr: 0.001
  algorithm:
    dqn:
      timesteps_per_reset: 1000000
      batch_size: 256
      target_network_update_frequency: 5
      max_grad_norm: 5.0
      gamma: 0.99
      reset_exploration_times: 0
      exploration_fraction: 0.99
      eps_start: 0.75
      eps_end: 0.0
      warmup_turns: 2560
      q_value_clipping: 5.0
      targets:
        tau: 0.03
        alpha: 0.9
        clipping: -1.0
      buffer:
        backend:
          buffer_size: 25000
          device: cpu
          alpha: 0.6
          beta: 0.4
          use_lap: false
  environment:
    guided_free_ratio: 0.5
    auto_skip: NONE
    normalize_rewards: true
    max_steps: 50
    user_patience: 5
    stop_when_reaching_goal: true
    stop_on_invalid_skip: false
    num_train_envs: 256
    num_val_envs: 100
    num_test_envs: 100
    goal_distance_mode: FULL_DISTANCE
    goal_distance_increment: 100
    sys_token: 'SYSTEM:'
    usr_token: 'USER:'
    sep_token: ''
  actions:
    in_state_space: true
    action_masking: true
  state:
    last_system_action: true
    beliefstate: true
    node_position: true
    node_type: true
    action_position: true
    node_text:
      active: true
      pooling: NONE
      noise_std: 0.0
    dialog_history:
      active: true
      pooling: NONE
      noise_std: 0.0
    action_text:
      active: true
      pooling: NONE
      noise_std: 0.0
    current_user_utterance:
      active: true
      pooling: NONE
      noise_std: 0.0
    initial_user_utterance:
      active: true
      pooling: NONE
      noise_std: 0.0