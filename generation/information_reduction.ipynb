{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/arbeitsdaten/asr-2/vaethdk/virtualenvs/cts_en/lib64/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-07 16:30:03 INFO: Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| constituency | wsj_bert |\n",
      "===========================\n",
      "\n",
      "2023-09-07 16:30:03 INFO: Using device: cuda\n",
      "2023-09-07 16:30:03 INFO: Loading: tokenize\n",
      "2023-09-07 16:30:09 INFO: Loading: pos\n",
      "2023-09-07 16:30:10 INFO: Loading: constituency\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-09-07 16:30:17 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "from stanza import DownloadMethod\n",
    "pipe = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency', package={'constituency': 'wsj_bert'}, \n",
    "                        model_dir=\"/mount/arbeitsdaten/asr-2/vaethdk/resources/weights/\", \n",
    "                        download_method=DownloadMethod.REUSE_RESOURCES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Dict, Iterable, Set\n",
    "from stanza.models.constituency.parse_tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(tree: Tree, labels:  Set[str]) -> Dict[str, int]:\n",
    "    # Returns the count per label\n",
    "    counters = defaultdict(lambda: 0)\n",
    "    for child in tree.children:\n",
    "        if child.label in labels:\n",
    "            counters[child.label] += 1\n",
    "        if not child.is_leaf():\n",
    "            child_counters = count_labels(child, labels)\n",
    "            for label in child_counters:\n",
    "                counters[label] += child_counters[label]\n",
    "    return counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def _prune(tree: Tree, label: str, instance: int = -1, instance_count = 0) -> Tuple[int, List[Tree]]:\n",
    "    candidates = []\n",
    "    current_instance_count = instance_count\n",
    "    for child in tree.children:\n",
    "        if child.label == label:\n",
    "            # found node for label\n",
    "            if instance < 0 or current_instance_count == instance:\n",
    "                # remove instance\n",
    "                current_instance_count += 1\n",
    "                # print(\"SKIPPING\", child, instance, current_instance_count)\n",
    "                continue\n",
    "            else:\n",
    "                current_instance_count += 1\n",
    "                # print(\"SEEN\", child, instance, current_instance_count)\n",
    "        if child.is_leaf():\n",
    "            # found word -> append\n",
    "            candidates += [child.label]\n",
    "        else:\n",
    "            # recurse\n",
    "            next_instance_count, next_candidates = _prune(child, label, instance, current_instance_count)\n",
    "            current_instance_count = next_instance_count\n",
    "            candidates += next_candidates\n",
    "    return current_instance_count, candidates\n",
    "\n",
    "def prune(tree: Tree, label: str, instance: int = -1) -> List[Tree]:\n",
    "    \"\"\" Remove \"label\" nodes from the tree.\n",
    "    Args:\n",
    "        instance (int): if < 0, removes ALL instances of 'label',\n",
    "                        else only the i-th given instance\n",
    "    \"\"\"\n",
    "    return _prune(tree, label, instance=instance, instance_count=0)[1]\n",
    "\n",
    "def extract_subtree(tree: Tree, label: str, instance: int = 0, instance_count = 0) -> List[Tree]:\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        instance (int): i-th subtree with 'label' to extract\n",
    "        intance_count (int): IGNORE, internal use only\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    for child in tree.children:\n",
    "        if child.label == label:\n",
    "            # found node for label\n",
    "            if instance_count == instance:\n",
    "                return child.leaf_labels()\n",
    "            instance_count += 1\n",
    "        else:\n",
    "            # recurse\n",
    "            candidates += extract_subtree(child, label, instance, instance_count)\n",
    "    return candidates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leafs_to_string(leafs: List[str]) -> str:\n",
    "    result = \" \".join(leafs)\n",
    "    old_length = 0\n",
    "    new_length = -1\n",
    "    while old_length != new_length:\n",
    "        old_length = len(result)\n",
    "        result = result.replace(\" ,\", \",\").replace(\" ?\", \"?\").replace(\" ;\", \";\").replace(\" !\", \"!\").replace(\" :\", \":\").replace(\" `\", \"`\").replace(\" '\", \"'\").replace(' \"', '\"').replace(' $', '$')\n",
    "        new_length = len(result)\n",
    "    old_length = 0\n",
    "    new_length = -1\n",
    "    while old_length != new_length:\n",
    "        # while we can contract punctuation, we should continue to do so\n",
    "        old_length = len(result)\n",
    "        result = result.replace(\",,\", \",\").replace(\"??\", \"?\").replace(\";;\", \";\").replace(\"!!\", \"!\").replace(\"::\", \":\").replace(\" `\", \"`\").replace(\"''\", \"'\").replace('\"\"', '\"').replace('$$', '$')\n",
    "        new_length = len(result)\n",
    "    return result.strip()\n",
    "    \n",
    "\n",
    "def realize_all_options(tree: Tree, label: str) -> Set[str]:\n",
    "    # realize all possible options\n",
    "    realizations = set([])\n",
    "    # count label frequency\n",
    "    label_count = count_labels(tree, labels=set([label]))\n",
    "    num_labels = label_count[label] if label in label_count else 0\n",
    "    for instance in range(num_labels):\n",
    "        realization = leafs_to_string(prune(tree, label, instance=instance))\n",
    "        if len(realization) > 4: # filter empty clauses (or clauses that contain only punctuation after pruning)\n",
    "            realizations.add(realization)\n",
    "    return realizations\n",
    "\n",
    "\n",
    "def extract_single_option(tree: Tree, label: str, instance: int = 0):\n",
    "    realizations = set([])\n",
    "    # count label frequency\n",
    "    label_count = count_labels(tree, labels=set([label])) \n",
    "    num_labels = label_count[label] if label in label_count else 0\n",
    "    if num_labels > 1:\n",
    "        # remove second instance\n",
    "        realization = leafs_to_string(extract_subtree(tree, label, instance=instance))\n",
    "        realizations.add(realization)\n",
    "    return realizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_options(tree: Tree, label: str):\n",
    "    for option in realize_all_options(tree, label):\n",
    "        print(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"Can I use more than two private cars for stretches longer than 100 miles, or is that usually not reimbursable?\"\n",
    "sentence2 = \"Should I use two cars to drive to the venue?\"\n",
    "sentence3 = \"Can I, using a brush, carefully glue and paint my pretty miniatures, or is this impossible?\"\n",
    "sentence4 = \"If I stay for longer than 5 days in Germany, am I still eligible for 500$ daily allowance?\"\n",
    "doc1 = pipe(sentence1)\n",
    "doc2 = pipe(sentence2)\n",
    "doc3 = pipe(sentence3)\n",
    "doc4 = pipe(sentence4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (S\n",
      "    (SQ\n",
      "      (MD Can)\n",
      "      (NP (PRP I))\n",
      "      (VP\n",
      "        (VB use)\n",
      "        (NP\n",
      "          (QP (JJR more) (IN than) (CD two))\n",
      "          (JJ private)\n",
      "          (NNS cars))\n",
      "        (PP\n",
      "          (IN for)\n",
      "          (NP\n",
      "            (NP (NNS stretches))\n",
      "            (ADJP\n",
      "              (ADJP (RBR longer))\n",
      "              (PP\n",
      "                (IN than)\n",
      "                (NP (CD 100) (NNS miles))))))))\n",
      "    (, ,)\n",
      "    (CC or)\n",
      "    (SQ\n",
      "      (VBZ is)\n",
      "      (NP (DT that))\n",
      "      (ADVP (RB usually))\n",
      "      (RB not)\n",
      "      (ADJP (JJ reimbursable)))\n",
      "    (. ?)))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc1.sentences:\n",
    "    print(sentence.constituency.pretty_print())\n",
    "    # print(type(sentence.constituency))\n",
    "    # print(Tree.get_compound_constituents([sentence.constituency]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (SQ\n",
      "    (MD Should)\n",
      "    (NP (PRP I))\n",
      "    (VP\n",
      "      (VB use)\n",
      "      (NP (CD two) (NNS cars))\n",
      "      (S\n",
      "        (VP\n",
      "          (TO to)\n",
      "          (VP\n",
      "            (VB drive)\n",
      "            (PP\n",
      "              (IN to)\n",
      "              (NP (DT the) (NN venue)))))))\n",
      "    (. ?)))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc2.sentences:\n",
    "    print(sentence.constituency.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (S\n",
      "    (SQ\n",
      "      (MD Can)\n",
      "      (NP (PRP I))\n",
      "      (, ,)\n",
      "      (S\n",
      "        (VP\n",
      "          (VBG using)\n",
      "          (NP (DT a) (NN brush))))\n",
      "      (, ,)\n",
      "      (ADVP (RB carefully))\n",
      "      (VP\n",
      "        (NN glue)\n",
      "        (CC and)\n",
      "        (VB paint)\n",
      "        (NP (PRP$ my) (JJ pretty) (NNS miniatures))))\n",
      "    (, ,)\n",
      "    (CC or)\n",
      "    (SQ\n",
      "      (VBZ is)\n",
      "      (NP (DT this))\n",
      "      (ADJP (JJ impossible)))\n",
      "    (. ?)))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc3.sentences:\n",
    "    print(sentence.constituency.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (SBARQ\n",
      "    (SBAR\n",
      "      (IN If)\n",
      "      (S\n",
      "        (NP (PRP I))\n",
      "        (VP\n",
      "          (VBP stay)\n",
      "          (PP\n",
      "            (IN for)\n",
      "            (NP\n",
      "              (QP (JJR longer) (IN than) (CD 5))\n",
      "              (NNS days)))\n",
      "          (PP\n",
      "            (IN in)\n",
      "            (NP (NNP Germany))))))\n",
      "    (, ,)\n",
      "    (VBP am)\n",
      "    (NP (PRP I))\n",
      "    (ADVP (RB still))\n",
      "    (ADJP\n",
      "      (JJ eligible)\n",
      "      (PP\n",
      "        (IN for)\n",
      "        (NP\n",
      "          (NML (CD 500) ($ $))\n",
      "          (JJ daily)\n",
      "          (NN allowance))))\n",
      "    (. ?)))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc4.sentences:\n",
    "    print(sentence.constituency.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I use more than two private cars for stretches longer than 100 miles, or is that usually not reimbursable?\n",
      "Can I use more than two cars for stretches longer than 100 miles, or is that usually not reimbursable?\n",
      "Can I use more than two private cars for stretches longer than 100 miles, or is that usually not?\n",
      "Should I use two cars to drive to the venue?\n",
      "Can I, using a brush, carefully glue and paint my pretty miniatures, or is this impossible?\n",
      "Can I, using a brush, carefully glue and paint my pretty miniatures, or is this?\n",
      "Can I, using a brush, carefully glue and paint my miniatures, or is this impossible?\n",
      "If I stay for longer than 5 days in Germany, am I still eligible for daily allowance?\n",
      "If I stay for longer than 5 days in Germany, am I still for daily allowance?\n",
      "If I stay for longer than 5 days in Germany, am I still eligible for allowance?\n"
     ]
    }
   ],
   "source": [
    "# Remove adjectives\n",
    "print(sentence1)\n",
    "print_all_options(doc1.sentences[0].constituency, \"JJ\")\n",
    "print(sentence2)\n",
    "print_all_options(doc2.sentences[0].constituency, \"JJ\")\n",
    "print(sentence3)\n",
    "print_all_options(doc3.sentences[0].constituency, \"JJ\")\n",
    "print(sentence4)\n",
    "print_all_options(doc4.sentences[0].constituency, \"JJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I use more than two private cars for stretches longer than 100 miles, or is that usually not reimbursable?\n",
      "Can I use more than two private cars, or is that usually not reimbursable?\n",
      "Can I use more than two private cars for stretches longer, or is that usually not reimbursable?\n",
      "Should I use two cars to drive to the venue?\n",
      "Should I use two cars to drive?\n",
      "Can I, using a brush, carefully glue and paint my pretty miniatures, or is this impossible?\n",
      "If I stay for longer than 5 days in Germany, am I still eligible for daily allowance?\n",
      "If I stay for longer than 5 days in Germany, am I still eligible?\n",
      "If I stay in Germany, am I still eligible for daily allowance?\n",
      "If I stay for longer than 5 days, am I still eligible for daily allowance?\n"
     ]
    }
   ],
   "source": [
    "# Remove prepositional phrase\n",
    "print(sentence1)\n",
    "print_all_options(doc1.sentences[0].constituency, \"PP\")\n",
    "print(sentence2)\n",
    "print_all_options(doc2.sentences[0].constituency, \"PP\")\n",
    "print(sentence3)\n",
    "print_all_options(doc3.sentences[0].constituency, \"PP\")\n",
    "print(sentence4)\n",
    "print_all_options(doc4.sentences[0].constituency, \"PP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I use more than two private cars for stretches longer than 100 miles, or is that usually not reimbursable?\n",
      "Can I use more than two private cars for stretches longer than 100 miles, or is that not reimbursable?\n",
      "Should I use two cars to drive to the venue?\n",
      "Can I, using a brush, carefully glue and paint my pretty miniatures, or is this impossible?\n",
      "Can I, using a brush, glue and paint my pretty miniatures, or is this impossible?\n",
      "If I stay for longer than 5 days in Germany, am I still eligible for daily allowance?\n",
      "If I stay for longer than 5 days in Germany, am I eligible for daily allowance?\n"
     ]
    }
   ],
   "source": [
    "# Remove adverb phrase\n",
    "print(sentence1)\n",
    "print_all_options(doc1.sentences[0].constituency, \"ADVP\")\n",
    "print(sentence2)\n",
    "print_all_options(doc2.sentences[0].constituency, \"ADVP\")\n",
    "print(sentence3)\n",
    "print_all_options(doc3.sentences[0].constituency, \"ADVP\")\n",
    "print(sentence4)\n",
    "print_all_options(doc4.sentences[0].constituency, \"ADVP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I use more than two private cars for stretches longer than 100 miles, or is that usually not reimbursable?\n",
      "Can I use private cars for stretches longer than 100 miles, or is that usually not reimbursable?\n",
      "Should I use two cars to drive to the venue?\n",
      "Can I, using a brush, carefully glue and paint my pretty miniatures, or is this impossible?\n",
      "If I stay for longer than 5 days in Germany, am I still eligible for daily allowance?\n",
      "If I stay for days in Germany, am I still eligible for daily allowance?\n"
     ]
    }
   ],
   "source": [
    "# Remove quantifier phrase\n",
    "print(sentence1)\n",
    "print_all_options(doc1.sentences[0].constituency, \"QP\")\n",
    "print(sentence2)\n",
    "print_all_options(doc2.sentences[0].constituency, \"QP\")\n",
    "print(sentence3)\n",
    "print_all_options(doc3.sentences[0].constituency, \"QP\")\n",
    "print(sentence4)\n",
    "print_all_options(doc4.sentences[0].constituency, \"QP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I use more than two private cars for stretches longer than 100 miles, or is that usually not reimbursable?\n",
      "Can I use more than two private cars for stretches longer than 100 miles, or is that not reimbursable?\n",
      "Can I use more than two private cars for stretches longer than 100 miles, or is that usually reimbursable?\n",
      "Should I use two cars to drive to the venue?\n",
      "Can I, using a brush, carefully glue and paint my pretty miniatures, or is this impossible?\n",
      "Can I, using a brush, glue and paint my pretty miniatures, or is this impossible?\n",
      "If I stay for longer than 5 days in Germany, am I still eligible for 500$ daily allowance?\n",
      "If I stay for longer than 5 days in Germany, am I eligible for 500$ daily allowance?\n"
     ]
    }
   ],
   "source": [
    "# Remove adverbs??\n",
    "print(sentence1)\n",
    "print_all_options(doc1.sentences[0].constituency, \"RB\")\n",
    "print(sentence2)\n",
    "print_all_options(doc2.sentences[0].constituency, \"RB\")\n",
    "print(sentence3)\n",
    "print_all_options(doc3.sentences[0].constituency, \"RB\")\n",
    "print(sentence4)\n",
    "print_all_options(doc4.sentences[0].constituency, \"RB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I use more than two private cars for stretches longer than 100 miles, or is that usually not reimbursable?\n",
      "Can I use more than two private cars for stretches longer than miles, or is that usually not reimbursable?\n",
      "Can I use more than private cars for stretches longer than 100 miles, or is that usually not reimbursable?\n",
      "Should I use two cars to drive to the venue?\n",
      "Should I use cars to drive to the venue?\n",
      "Can I, using a brush, carefully glue and paint my pretty miniatures, or is this impossible?\n",
      "If I stay for longer than 5 days in Germany, am I still eligible for 500$ daily allowance?\n",
      "If I stay for longer than days in Germany, am I still eligible for 500$ daily allowance?\n",
      "If I stay for longer than 5 days in Germany, am I still eligible for$ daily allowance?\n"
     ]
    }
   ],
   "source": [
    "# Remove cardinal numbers ??\n",
    "print(sentence1)\n",
    "print_all_options(doc1.sentences[0].constituency, \"CD\")\n",
    "print(sentence2)\n",
    "print_all_options(doc2.sentences[0].constituency, \"CD\")\n",
    "print(sentence3)\n",
    "print_all_options(doc3.sentences[0].constituency, \"CD\")\n",
    "print(sentence4)\n",
    "print_all_options(doc4.sentences[0].constituency, \"CD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I use more than two private cars for stretches longer than 100 miles, or is that usually not reimbursable?\n",
      "Should I use two cars to drive to the venue?\n",
      "Can I, using a brush, carefully glue and paint my pretty miniatures, or is this impossible?\n",
      "If I stay for longer than 5 days in Germany, am I still eligible for 500$ daily allowance?\n",
      "If I stay for longer than 5 days in Germany, am I still eligible for daily allowance?\n"
     ]
    }
   ],
   "source": [
    "# Remove nominal modifiers??\n",
    "print(sentence1)\n",
    "print_all_options(doc1.sentences[0].constituency, \"NML\")\n",
    "print(sentence2)\n",
    "print_all_options(doc2.sentences[0].constituency, \"NML\")\n",
    "print(sentence3)\n",
    "print_all_options(doc3.sentences[0].constituency, \"NML\")\n",
    "print(sentence4)\n",
    "print_all_options(doc4.sentences[0].constituency, \"NML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I use more than two private cars for stretches longer than 100 miles, or is that usually not reimbursable?\n",
      "Should I use two cars to drive to the venue?\n",
      "Should I use two cars?\n",
      "Can I, using a brush, carefully glue and paint my pretty miniatures, or is this impossible?\n",
      "Can I, carefully glue and paint my pretty miniatures, or is this impossible?\n",
      "If I stay for longer than 5 days in Germany, am I still eligible for 500$ daily allowance?\n",
      "If, am I still eligible for 500$ daily allowance?\n"
     ]
    }
   ],
   "source": [
    "# Remove simple declarative clauses\n",
    "print(sentence1)\n",
    "print_all_options(doc1.sentences[0].constituency, \"S\")\n",
    "print(sentence2)\n",
    "print_all_options(doc2.sentences[0].constituency, \"S\")\n",
    "print(sentence3)\n",
    "print_all_options(doc3.sentences[0].constituency, \"S\")\n",
    "print(sentence4)\n",
    "print_all_options(doc4.sentences[0].constituency, \"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I use more than two private cars for stretches longer than 100 miles, or is that usually not reimbursable?\n",
      "Can I use more than two private cars for stretches longer than 100 miles\n",
      "Should I use two cars to drive to the venue?\n",
      "Can I, using a brush, carefully glue and paint my pretty miniatures, or is this impossible?\n",
      "Can I, using a brush, carefully glue and paint my pretty miniatures\n",
      "If I stay for longer than 5 days in Germany, am I still eligible for 500$ daily allowance?\n"
     ]
    }
   ],
   "source": [
    "# Remove all questions after first question\n",
    "print(sentence1)\n",
    "for sentence in extract_single_option(doc1.sentences[0].constituency, \"SQ\", instance=0):\n",
    "    print(sentence)\n",
    "print(sentence2)\n",
    "for sentence in extract_single_option(doc2.sentences[0].constituency, \"SQ\", instance=0):\n",
    "    print(sentence)\n",
    "print(sentence3)\n",
    "for sentence in extract_single_option(doc3.sentences[0].constituency, \"SQ\", instance=0):\n",
    "    print(sentence)\n",
    "print(sentence4)\n",
    "for sentence in extract_single_option(doc4.sentences[0].constituency, \"SQ\", instance=0):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def augment_question_data(json_question_filepath: str, output_filename: str):\n",
    "    all_augmentations = defaultdict(lambda: set([]))\n",
    "    with open(json_question_filepath, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        new_data = deepcopy(data)\n",
    "        for key in tqdm(data):\n",
    "            # analyze question\n",
    "            question = data[key]['text']\n",
    "            doc = pipe(question)\n",
    "            \n",
    "            question_augmentations = set([])\n",
    "            for sentence_idx, sentence in enumerate(doc.sentences):\n",
    "                # apply augmentations per sentence\n",
    "                sentence_augmentations = realize_all_options(sentence.constituency, \"JJ\")\n",
    "                sentence_augmentations = sentence_augmentations.union(realize_all_options(sentence.constituency, \"PP\"))\n",
    "                sentence_augmentations = sentence_augmentations.union(realize_all_options(sentence.constituency, \"ADVP\"))\n",
    "                sentence_augmentations = sentence_augmentations.union(realize_all_options(sentence.constituency, \"QP\"))\n",
    "                sentence_augmentations = sentence_augmentations.union(realize_all_options(sentence.constituency, \"RB\"))\n",
    "                sentence_augmentations = sentence_augmentations.union(realize_all_options(sentence.constituency, \"CD\"))\n",
    "                sentence_augmentations = sentence_augmentations.union(realize_all_options(sentence.constituency, \"NML\"))\n",
    "                sentence_augmentations = sentence_augmentations.union(realize_all_options(sentence.constituency, \"S\"))\n",
    "                sentence_augmentations = sentence_augmentations.union(extract_single_option(sentence.constituency, \"SQ\", instance=0))\n",
    "\n",
    "                if len(question_augmentations) > 0:\n",
    "                    # cross-product between all sentence realisations until now and next sentence realizations\n",
    "                    new_augmentations = set([])\n",
    "                    for sentences_so_far in question_augmentations:\n",
    "                        for next_sentence in sentence_augmentations:\n",
    "                            new_augmentations.add(sentences_so_far + \" \" + next_sentence)\n",
    "                    question_augmentations = new_augmentations\n",
    "                else:\n",
    "                    # initialize question list (this is the first sentence)\n",
    "                    question_augmentations = question_augmentations.union(sentence_augmentations)\n",
    "            \n",
    "            # create new question entries in data with final augmentations\n",
    "            for augmentation in question_augmentations:\n",
    "                new_key = str(time.time()).replace(\".\", \"\")\n",
    "                new_data[new_key] = deepcopy(data[key])\n",
    "                new_data[new_key]['text'] = augmentation\n",
    "                all_augmentations[key].add(augmentation)\n",
    "            \n",
    "    with open(output_filename, \"w\") as f:\n",
    "        json.dump(new_data, f)\n",
    "                \n",
    "    return all_augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [02:58<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL Augmentations 2881\n",
      "MAX Augmentations 10\n",
      "MIN Augmentations 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "v1_augmentations = augment_question_data(\"../resources/en/generated/train_questions_v1.json\", \"./train_questions_v1_ling.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cts_en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
